{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-zLlHpGaWm7f"
   },
   "source": [
    "Setting up the connection with the Google Collab notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E8_i3XQv_CNU",
    "outputId": "b3c0e88e-14d1-44b1-9f0b-cfd48676c7f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n",
      "Additional_Resources  Complete_Sources\tModel_Scores.gsheet  Tutorials\n",
      "Assignment_Overview   Dev-set\t\tTest-set\n"
     ]
    }
   ],
   "source": [
    "# connect information in the google drive to this collab session and change the working directory\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')\n",
    "# Changing the working directory to the Assignment folder\n",
    "import os\n",
    "os.chdir('/content/drive/MyDrive/CA684_Assignment/')\n",
    "!ls # Listing the files in working directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QacBu6HAkYQ5"
   },
   "source": [
    "Importing and loading the required set of packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pT-5CcF5-ZIi",
    "outputId": "9ccb8077-50e8-4603-c261-e985e42999e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting https://github.com/chengs/tqdm/archive/colab.zip\n",
      "\u001b[?25l  Downloading https://github.com/chengs/tqdm/archive/colab.zip\n",
      "\u001b[K     \\ 225kB 1.5MB/s\n",
      "\u001b[?25hBuilding wheels for collected packages: tqdm\n",
      "  Building wheel for tqdm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for tqdm: filename=tqdm-4.28.1-py2.py3-none-any.whl size=47868 sha256=89f5c44747efbecbd44bfe73621b7da1dfd86553e13a6c495058720d146f72af\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-258fnlm1/wheels/41/18/ee/d5dd158441b27965855b1bbae03fa2d8a91fe645c01b419896\n",
      "Successfully built tqdm\n",
      "\u001b[31mERROR: spacy 2.2.4 has requirement tqdm<5.0.0,>=4.38.0, but you'll have tqdm 4.28.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: fbprophet 0.7.1 has requirement tqdm>=4.36.1, but you'll have tqdm 4.28.1 which is incompatible.\u001b[0m\n",
      "Installing collected packages: tqdm\n",
      "  Found existing installation: tqdm 4.41.1\n",
      "    Uninstalling tqdm-4.41.1:\n",
      "      Successfully uninstalled tqdm-4.41.1\n",
      "Successfully installed tqdm-4.28.1\n",
      "Collecting pyprind\n",
      "  Downloading https://files.pythonhosted.org/packages/ab/b3/1f12ebc5009c65b607509393ad98240728b4401bc3593868fb161fdd3760/PyPrind-2.11.3-py2.py3-none-any.whl\n",
      "Installing collected packages: pyprind\n",
      "Successfully installed pyprind-2.11.3\n"
     ]
    }
   ],
   "source": [
    "!pip install --force https://github.com/chengs/tqdm/archive/colab.zip\n",
    "!pip install pyprind\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import pyprind\n",
    "from string import punctuation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import ensemble\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "import xgboost as xgb\n",
    "from keras import Sequential\n",
    "from keras import preprocessing\n",
    "from keras import layers\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KmY73LVvjvmI"
   },
   "source": [
    "Functions used for loading the feature set and calculating spearman score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Jl0jKPGkSJVm"
   },
   "outputs": [],
   "source": [
    "# Function to calculate the Spearman Correlation score\n",
    "def Get_score(Y_pred,Y_true):\n",
    "    '''Calculate the Spearmann\"s correlation coefficient'''\n",
    "    Y_pred = np.squeeze(Y_pred)\n",
    "    Y_true = np.squeeze(Y_true)\n",
    "    if Y_pred.shape != Y_true.shape:\n",
    "        print('Input shapes don\\'t match!')\n",
    "    else:\n",
    "        if len(Y_pred.shape) == 1:\n",
    "            Res = pd.DataFrame({'Y_true':Y_true,'Y_pred':Y_pred})\n",
    "            score_mat = Res[['Y_true','Y_pred']].corr(method='spearman',min_periods=1)\n",
    "            print('The Spearman\\'s correlation coefficient is: %.3f' % score_mat.iloc[1][0])\n",
    "        else:\n",
    "            for ii in range(Y_pred.shape[1]):\n",
    "                Get_score(Y_pred[:,ii],Y_true[:,ii])\n",
    "\n",
    "# Function to read C3D feature\n",
    "def read_C3D(fname):\n",
    "    \"\"\"Scan vectors from file\"\"\"\n",
    "    with open(fname) as f:\n",
    "        for line in f:\n",
    "            C3D =[float(item) for item in line.split()] # convert to float type, using default separator\n",
    "    return C3D\n",
    "  \n",
    "# Function to read HMP feature\n",
    "def read_HMP(fname):\n",
    "    \"\"\"Scan HMP(Histogram of Motion Patterns) features from file\"\"\"\n",
    "    with open(fname) as f:\n",
    "        for line in f:\n",
    "            pairs=line.split()\n",
    "            HMP_temp = { int(p.split(':')[0]) : float(p.split(':')[1]) for p in pairs}\n",
    "    # there are 6075 bins, fill zeros\n",
    "    HMP = np.zeros(6075)\n",
    "    for idx in HMP_temp.keys():\n",
    "        HMP[idx-1] = HMP_temp[idx]            \n",
    "    return HMP\n",
    "\n",
    "# Function to read LBP feature\n",
    "def read_LBP(fname):\n",
    "    \"\"\"Scan vectors from file\"\"\"\n",
    "    with open(fname) as f:\n",
    "        for line in f:\n",
    "            LBP =[float(item) for item in line.split()] # convert to float type, using default separator\n",
    "    return LBP\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vfZPyS42XTXp"
   },
   "source": [
    "Loading the ground truth file from the Dev set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "6ofB-jWR0xdq"
   },
   "outputs": [],
   "source": [
    "# load the ground truth values\n",
    "GT = pd.read_csv('./Dev-set/Ground-truth/ground-truth.csv')\n",
    "vid = GT.video.values  # list the video filenames from the ground truth "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "XeLUSb711PA8",
    "outputId": "570b241b-b727-4b49-9da4-65f75cf97e9b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video</th>\n",
       "      <th>short-term_memorability</th>\n",
       "      <th>nb_short-term_annotations</th>\n",
       "      <th>long-term_memorability</th>\n",
       "      <th>nb_long-term_annotations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>video3.webm</td>\n",
       "      <td>0.924</td>\n",
       "      <td>34</td>\n",
       "      <td>0.846</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>video4.webm</td>\n",
       "      <td>0.923</td>\n",
       "      <td>33</td>\n",
       "      <td>0.667</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>video6.webm</td>\n",
       "      <td>0.863</td>\n",
       "      <td>33</td>\n",
       "      <td>0.700</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>video8.webm</td>\n",
       "      <td>0.922</td>\n",
       "      <td>33</td>\n",
       "      <td>0.818</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>video10.webm</td>\n",
       "      <td>0.950</td>\n",
       "      <td>34</td>\n",
       "      <td>0.900</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          video  ...  nb_long-term_annotations\n",
       "0   video3.webm  ...                        13\n",
       "1   video4.webm  ...                        12\n",
       "2   video6.webm  ...                        10\n",
       "3   video8.webm  ...                        11\n",
       "4  video10.webm  ...                        10\n",
       "\n",
       "[5 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GT.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z1cVc6Hpl1uy"
   },
   "source": [
    "Loading the features into a python dataframe from the drive (one time load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2C9HGpdo7-5b",
    "outputId": "00cd4bfe-eeff-40ce-dfa0-29062bf3dd3b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting the C3D feature\n",
    "c3d_features = pd.DataFrame(columns=['video','C3D'])\n",
    "for i in range(6000):\n",
    "  c3d_features = c3d_features.append({'video': vid[i], 'C3D': read_C3D('./Dev-set/C3D/' + vid[i].split('.')[0] + '.txt')}, ignore_index=True)\n",
    "c3d_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jsHa_Q4YmDTq",
    "outputId": "cd04dea6-8a3d-40e5-baea-21b408a7c1f2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000, 2)"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting the HMP feature\n",
    "hmp_features = pd.DataFrame(columns=['video','HMP'])\n",
    "for i in range(6000):\n",
    "  hmp_features = hmp_features.append({'video': vid[i], 'HMP': read_HMP('./Dev-set/HMP/' + vid[i].split('.')[0] + '.txt')}, ignore_index=True)\n",
    "hmp_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GGxaF5Y8X4iq",
    "outputId": "27dcf12d-fc32-4992-f41f-2d3890a31bb0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000, 2)"
      ]
     },
     "execution_count": 44,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting the LBP feature\n",
    "lbp_features1 = pd.DataFrame(columns=['video','LBP'])\n",
    "lbp_features2 = pd.DataFrame(columns=['video','LBP'])\n",
    "lbp_features3 = pd.DataFrame(columns=['video','LBP'])\n",
    "for i in range(6000):\n",
    "  lbp_features1 = lbp_features1.append({'video': vid[i], 'LBP': read_LBP('./Dev-set/LBP/' + vid[i].split('.')[0] + '-0.txt')}, ignore_index=True)\n",
    "  lbp_features2 = lbp_features2.append({'video': vid[i], 'LBP': read_LBP('./Dev-set/LBP/' + vid[i].split('.')[0] + '-56.txt')}, ignore_index=True)\n",
    "  lbp_features3 = lbp_features3.append({'video': vid[i], 'LBP': read_LBP('./Dev-set/LBP/' + vid[i].split('.')[0] + '-112.txt')}, ignore_index=True)\n",
    "lbp_features1.shape\n",
    "lbp_features2.shape\n",
    "lbp_features3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jbxz6rMUutAj"
   },
   "source": [
    "Saving and Loading the extracted features using the pickle files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FseG0URKdrfc"
   },
   "outputs": [],
   "source": [
    "#----------- Saving the features to the drive ------------\n",
    "\n",
    "os.chdir('/content/drive/MyDrive')\n",
    "# Saving the C3D feature in Google Drive to reuse later  \n",
    "c3d_features.to_pickle('./C3D_Features.pickle')\n",
    "# Saving the HMP feature in Google Drive to reuse later  \n",
    "hmp_features.to_pickle('./HMP_Features.pickle')\n",
    "# Saving the LBP 0 frame feature in Google Drive to reuse later  \n",
    "lbp_features1.to_pickle('./LBP_0Frame_Features.pickle')\n",
    "# Saving the LBP 56 frame feature in Google Drive to reuse later  \n",
    "lbp_features2.to_pickle('./LBP_56Frame_Features.pickle')\n",
    "# Saving the LBP 112 frame feature in Google Drive to reuse later  \n",
    "lbp_features3.to_pickle('./LBP_112Frame_Features.pickle')\n",
    "# Changing the working directory\n",
    "os.chdir('/content/drive/MyDrive/CA684_Assignment/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "MZYG5repUwL_"
   },
   "outputs": [],
   "source": [
    "#----------- Loading the features from the drive ------------\n",
    "\n",
    "os.chdir('/content/drive/MyDrive')\n",
    "# Load C3D feature back in memory session\n",
    "c3d_features = pd.read_pickle('./C3D_Features.pickle')\n",
    "# Load HMP feature back in memory session\n",
    "hmp_features = pd.read_pickle('./HMP_Features.pickle')\n",
    "# Load LBP frame features back in memory session\n",
    "lbp_0frame_features = pd.read_pickle('./LBP_0Frame_Features.pickle')\n",
    "lbp_56frame_features = pd.read_pickle('./LBP_56Frame_Features.pickle')\n",
    "lbp_112frame_features = pd.read_pickle('./LBP_112Frame_Features.pickle')\n",
    "# Changing the working directory\n",
    "os.chdir('/content/drive/MyDrive/CA684_Assignment/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "266ihOf-4Vb-"
   },
   "source": [
    "Extracting the values of features from 1-D numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "51Cfl57y2IdN",
    "outputId": "08df402a-5ad5-4fce-dfe4-32b952c702aa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000, 101)"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# C3D feature value extracted\n",
    "sequences = c3d_features['C3D']\n",
    "C3D_seq = np.zeros((len(sequences),len(c3d_features.loc[0,'C3D'])))\n",
    "for i in range(len(sequences)):\n",
    "    n = len(sequences[i])\n",
    "    C3D_seq[i,-n:] = sequences[i]\n",
    "C3D_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PP_YKmnq2_n-",
    "outputId": "d0e247b2-bc9a-4eaf-b917-76db15d5a0e4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000, 6075)"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# HMP feature value extracted\n",
    "sequences = hmp_features['HMP']\n",
    "HMP_seq = np.zeros((len(sequences),len(hmp_features.loc[0,'HMP'])))\n",
    "for i in range(len(sequences)):\n",
    "    n = len(sequences[i])\n",
    "    HMP_seq[i,-n:] = sequences[i]\n",
    "HMP_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0FLBkEz2Nbdp",
    "outputId": "327a24d4-b0d7-4b8f-bd0f-72cfdc1e04ce"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000, 366)"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LBP feature value extracted\n",
    "def LBP_Frame(lbp_features) :\n",
    "  sequences = lbp_features['LBP']\n",
    "  LBP_seq = np.zeros((len(sequences),len(lbp_features.loc[0,'LBP'])))\n",
    "  for i in range(len(sequences)):\n",
    "      n = len(sequences[i])\n",
    "      LBP_seq[i,-n:] = sequences[i]\n",
    "  return LBP_seq\n",
    "LBP_seq = np.concatenate((LBP_Frame(lbp_0frame_features),LBP_Frame(lbp_56frame_features),LBP_Frame(lbp_112frame_features)),axis = 1)\n",
    "LBP_seq.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r1ZJr4HagrP5"
   },
   "source": [
    "PCA technique to reduce the dimensionality of HMP feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rNWUwRdeM5rZ",
    "outputId": "33d62a46-08d7-4766-ca84-70ffc1baa69e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000, 178)"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "#pca = PCA(n_components=256)\n",
    "# preserving the 99.9% of the variance i.e. reduced components explains 99.9% variance of the data \n",
    "pca = PCA(0.999)\n",
    "HMP_seq_PCA = pd.DataFrame(pca.fit_transform(HMP_seq))\n",
    "HMP_seq_PCA.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fUr6lPdAV43j"
   },
   "source": [
    "Merging the feature set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GWQaG5q55Hu2",
    "outputId": "c0e1b455-ab69-4047-f221-460956fbdfcd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 279)\n",
      "(6000, 467)\n",
      "(6000, 645)\n"
     ]
    }
   ],
   "source": [
    "# merging the C3D and reduced HMP feature set\n",
    "C3D_HMP = np.concatenate((C3D_seq,HMP_seq_PCA), axis = 1)\n",
    "\n",
    "# merging the C3D and LBP feature set\n",
    "C3D_LBP = np.concatenate((C3D_seq,LBP_seq), axis = 1)\n",
    "\n",
    "# merging the C3D, LBP and reduced HMP feature set\n",
    "C3D_LBP_HMP = np.concatenate((C3D_seq,LBP_seq,HMP_seq_PCA), axis = 1)\n",
    "\n",
    "print(C3D_HMP.shape)\n",
    "print(C3D_LBP.shape)\n",
    "print(C3D_LBP_HMP.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oeDERCxNLJsS"
   },
   "source": [
    "Feature set used to predict the memorability and spearman score\n",
    "1. C3D\n",
    "2. HMP\n",
    "3. LBP\n",
    "4. C3D & HMP\n",
    "5. C3D & LBP\n",
    "6. C3D, LBP & HMP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F9wDsmz4O6rq"
   },
   "source": [
    "Models used to check the spearman score\n",
    "1. K nearest neighbour\n",
    "2. Random forest\n",
    "3. Support vector regressor\n",
    "4. Nueral network\n",
    "5. Gradient boosting regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0eq7U5ew1No6"
   },
   "source": [
    "###Using C3D feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jD2-nRu405LW"
   },
   "source": [
    "Setting up the DV (Y) and IDVs (X) along with train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "id": "zIYI6AYi05Lg"
   },
   "outputs": [],
   "source": [
    "Y = GT[['short-term_memorability','long-term_memorability']].values\n",
    "st_Y = GT[['short-term_memorability']].values\n",
    "lt_Y = GT[['long-term_memorability']].values\n",
    "X = C3D_seq \n",
    "X_train, X_test, Y_train, Y_test = train_test_split( X, Y, test_size=0.2, random_state = 42) \n",
    "st_X_train,st_X_test,st_Y_train,st_Y_test = train_test_split(X,st_Y,test_size=0.2,random_state=40)\n",
    "lt_X_train,lt_X_test,lt_Y_train,lt_Y_test = train_test_split(X,lt_Y,test_size=0.2,random_state=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "COIiIWv605Lg"
   },
   "source": [
    "KNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c_CJPgsi05Lh",
    "outputId": "bc4e35e1-128f-4439-d1a7-9aad893f4a34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Spearman's correlation coefficient is: 0.251\n",
      "The Spearman's correlation coefficient is: 0.097\n"
     ]
    }
   ],
   "source": [
    "knnRegressor = KNeighborsRegressor(n_neighbors = 77)\n",
    "knnRegressor.fit(X_train, Y_train)\n",
    "y_pred = knnRegressor.predict(X_test)\n",
    "Get_score(y_pred, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zO4LCf1N05Lh"
   },
   "source": [
    "Random Forest ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Op69L3Qr05Li",
    "outputId": "d92f5fc0-9d1d-4084-e49d-e3587a149d48"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 100\n",
      "building tree 3 of 100\n",
      "building tree 4 of 100\n",
      "building tree 5 of 100\n",
      "building tree 6 of 100\n",
      "building tree 7 of 100\n",
      "building tree 8 of 100\n",
      "building tree 9 of 100\n",
      "building tree 10 of 100\n",
      "building tree 11 of 100\n",
      "building tree 12 of 100\n",
      "building tree 13 of 100\n",
      "building tree 14 of 100\n",
      "building tree 15 of 100\n",
      "building tree 16 of 100\n",
      "building tree 17 of 100\n",
      "building tree 18 of 100\n",
      "building tree 19 of 100\n",
      "building tree 20 of 100\n",
      "building tree 21 of 100\n",
      "building tree 22 of 100\n",
      "building tree 23 of 100\n",
      "building tree 24 of 100\n",
      "building tree 25 of 100\n",
      "building tree 26 of 100\n",
      "building tree 27 of 100\n",
      "building tree 28 of 100\n",
      "building tree 29 of 100\n",
      "building tree 30 of 100\n",
      "building tree 31 of 100\n",
      "building tree 32 of 100\n",
      "building tree 33 of 100\n",
      "building tree 34 of 100\n",
      "building tree 35 of 100\n",
      "building tree 36 of 100\n",
      "building tree 37 of 100\n",
      "building tree 38 of 100\n",
      "building tree 39 of 100\n",
      "building tree 40 of 100\n",
      "building tree 41 of 100\n",
      "building tree 42 of 100\n",
      "building tree 43 of 100\n",
      "building tree 44 of 100\n",
      "building tree 45 of 100\n",
      "building tree 46 of 100\n",
      "building tree 47 of 100\n",
      "building tree 48 of 100\n",
      "building tree 49 of 100\n",
      "building tree 50 of 100\n",
      "building tree 51 of 100\n",
      "building tree 52 of 100\n",
      "building tree 53 of 100\n",
      "building tree 54 of 100\n",
      "building tree 55 of 100\n",
      "building tree 56 of 100\n",
      "building tree 57 of 100\n",
      "building tree 58 of 100\n",
      "building tree 59 of 100\n",
      "building tree 60 of 100\n",
      "building tree 61 of 100\n",
      "building tree 62 of 100\n",
      "building tree 63 of 100\n",
      "building tree 64 of 100\n",
      "building tree 65 of 100\n",
      "building tree 66 of 100\n",
      "building tree 67 of 100\n",
      "building tree 68 of 100\n",
      "building tree 69 of 100\n",
      "building tree 70 of 100\n",
      "building tree 71 of 100\n",
      "building tree 72 of 100\n",
      "building tree 73 of 100\n",
      "building tree 74 of 100\n",
      "building tree 75 of 100\n",
      "building tree 76 of 100\n",
      "building tree 77 of 100\n",
      "building tree 78 of 100\n",
      "building tree 79 of 100\n",
      "building tree 80 of 100\n",
      "building tree 81 of 100\n",
      "building tree 82 of 100\n",
      "building tree 83 of 100\n",
      "building tree 84 of 100\n",
      "building tree 85 of 100\n",
      "building tree 86 of 100\n",
      "building tree 87 of 100\n",
      "building tree 88 of 100\n",
      "building tree 89 of 100\n",
      "building tree 90 of 100\n",
      "building tree 91 of 100\n",
      "building tree 92 of 100\n",
      "building tree 93 of 100\n",
      "building tree 94 of 100\n",
      "building tree 95 of 100\n",
      "building tree 96 of 100\n",
      "building tree 97 of 100\n",
      "building tree 98 of 100\n",
      "building tree 99 of 100\n",
      "building tree 100 of 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:   43.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
       "                      random_state=42, verbose=2, warm_start=False)"
      ]
     },
     "execution_count": 52,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestRegressor(n_estimators=100,random_state=42,verbose=2)\n",
    "rf.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4uUP-Ysr05Li",
    "outputId": "c35f06be-e52f-4b4b-aad4-aa5d43ee9a01"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "rf_pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YqhnGoeh05Li",
    "outputId": "3bcf94a5-e7bb-4896-c4d0-06398f286311"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Spearman's correlation coefficient is: 0.314\n",
      "The Spearman's correlation coefficient is: 0.117\n"
     ]
    }
   ],
   "source": [
    "Get_score(rf_pred, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PYGTWZvR05Lj"
   },
   "source": [
    "Building Neural Models from Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "ltAkvUTD05Lj"
   },
   "outputs": [],
   "source": [
    "# add dropout - Helps prevent overfitting\n",
    "# add regularizers - Regularizers allow to apply penalties on layer parameters or layer activity during optimization.\n",
    "# activations - Used to determine the output of network. It maps the resulting values in between 0 to 1 or -1 to 1 etc. (depending upon the function).\n",
    "model = Sequential() # The Sequential model is a linear stack of layers.\n",
    "model.add(layers.Dense(10,activation='relu',kernel_regularizer=regularizers.l2(0.0005),input_shape=(101,))) # Just your regular densely-connected NN layer.\n",
    "model.add(layers.Dropout(0.5)) #Dropout consists in randomly setting a fraction rate of input units to 0 at each update during training; helps prevent overfitting.\n",
    "model.add(layers.Dense(10,activation='relu',kernel_regularizer=regularizers.l2(0.0005)))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(2,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zXpCK9mi05Lj",
    "outputId": "3be28cfc-b295-4c93-ba9f-3f0ed66b0ba8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "150/150 [==============================] - 1s 1ms/step - loss: 0.0984 - accuracy: 0.6621\n",
      "Epoch 2/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0330 - accuracy: 0.6820\n",
      "Epoch 3/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0237 - accuracy: 0.6988\n",
      "Epoch 4/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0201 - accuracy: 0.7004\n",
      "Epoch 5/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0187 - accuracy: 0.6944\n",
      "Epoch 6/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0176 - accuracy: 0.6962\n",
      "Epoch 7/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0159 - accuracy: 0.6950\n",
      "Epoch 8/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0153 - accuracy: 0.7031\n",
      "Epoch 9/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0148 - accuracy: 0.7022\n",
      "Epoch 10/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0145 - accuracy: 0.6988\n",
      "Epoch 11/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0141 - accuracy: 0.7094\n",
      "Epoch 12/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0142 - accuracy: 0.6977\n",
      "Epoch 13/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0141 - accuracy: 0.7020\n",
      "Epoch 14/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0139 - accuracy: 0.7079\n",
      "Epoch 15/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0136 - accuracy: 0.7028\n",
      "Epoch 16/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0139 - accuracy: 0.7045\n",
      "Epoch 17/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0137 - accuracy: 0.6975\n",
      "Epoch 18/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0137 - accuracy: 0.7008\n",
      "Epoch 19/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0134 - accuracy: 0.7083\n",
      "Epoch 20/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0136 - accuracy: 0.7101\n",
      "The Spearman's correlation coefficient is: 0.266\n",
      "The Spearman's correlation coefficient is: 0.121\n"
     ]
    }
   ],
   "source": [
    "# compile the model \n",
    "model.compile(optimizer='rmsprop',loss='mse',metrics=['accuracy'])\n",
    "# training the model \n",
    "history = model.fit(X_train,Y_train,epochs=20)\n",
    "predictions = model.predict(X_test)\n",
    "Get_score(predictions, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G4t8U45p05Lj"
   },
   "source": [
    "SVR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "tW8Y8acJ05Lk"
   },
   "outputs": [],
   "source": [
    "st_X = StandardScaler()\n",
    "st_Y = StandardScaler()\n",
    "st_X_train = st_X.fit_transform(st_X_train)\n",
    "st_Y_train = st_Y.fit_transform(st_Y_train)\n",
    "lt_X = StandardScaler()\n",
    "lt_Y = StandardScaler()\n",
    "lt_X_train = lt_X.fit_transform(lt_X_train)\n",
    "lt_Y_train = lt_Y.fit_transform(lt_Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dpRCP1pc05Lk",
    "outputId": "bf57373e-793c-4fe4-efb3-2dd2dd6322da"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
       "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 61,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st_regressor = SVR(kernel = 'rbf')\n",
    "st_regressor.fit(st_X_train, st_Y_train)\n",
    "lt_regressor = SVR(kernel = 'rbf')\n",
    "lt_regressor.fit(lt_X_train,lt_Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "bJVj9nd405Lk"
   },
   "outputs": [],
   "source": [
    "st_pred = st_regressor.predict(st_X_test)\n",
    "st_pred = st_Y.inverse_transform(st_pred)\n",
    "lt_pred = lt_regressor.predict(lt_X_test)\n",
    "lt_pred = lt_Y.inverse_transform(lt_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XZdJBQwt05Lk",
    "outputId": "641d1b00-d624-42af-ece8-1fb2d34fc4c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Spearman's correlation coefficient is: 0.242\n",
      "The Spearman's correlation coefficient is: 0.107\n"
     ]
    }
   ],
   "source": [
    "Get_score(st_pred, st_Y_test)\n",
    "Get_score(lt_pred, lt_Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4-Eazc0u05Ll"
   },
   "source": [
    "XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HfiXVrh3a8X0",
    "outputId": "873c3356-f58b-4239-98a1-f880e16cd5ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:44:12] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[13:45:25] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "             importance_type='gain', learning_rate=0.01, loss='lad',\n",
       "             max_delta_step=0, max_depth=12, min_child_weight=1,\n",
       "             min_samples_split=2, missing=None, n_estimators=650, n_jobs=1,\n",
       "             nthread=None, objective='reg:linear', random_state=0, reg_alpha=0,\n",
       "             reg_lambda=1, scale_pos_weight=1, seed=None, silent=None,\n",
       "             subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 133,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'n_estimators':650, 'max_depth':12, 'min_samples_split':2, 'learning_rate':0.01, 'loss':'lad'}\n",
    "xgb_st = xgb.XGBRegressor(**params)\n",
    "xgb_lt = xgb.XGBRegressor(**params)\n",
    "xgb_st.fit(st_X_train, st_Y_train)\n",
    "xgb_lt.fit(lt_X_train, lt_Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tHYrS65sbINE",
    "outputId": "24b3eee4-01f7-4f06-ca51-9894b964647c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Spearman's correlation coefficient is: 0.295\n",
      "The Spearman's correlation coefficient is: 0.071\n"
     ]
    }
   ],
   "source": [
    "Get_score(xgb_st.predict(st_X_test), st_Y_test)\n",
    "Get_score(xgb_lt.predict(lt_X_test), lt_Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cBFZa96K5S-Q"
   },
   "source": [
    "## Using HMP feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qoHyssYuVcNz"
   },
   "source": [
    "Setting up the DV (Y) and IDVs (X) along with train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "id": "0sD5CAf5ux-V"
   },
   "outputs": [],
   "source": [
    "Y = GT[['short-term_memorability','long-term_memorability']].values\n",
    "st_Y = GT[['short-term_memorability']].values\n",
    "lt_Y = GT[['long-term_memorability']].values\n",
    "X = HMP_seq_PCA \n",
    "X_train, X_test, Y_train, Y_test = train_test_split( X, Y, test_size=0.2, random_state = 42) \n",
    "st_X_train,st_X_test,st_Y_train,st_Y_test = train_test_split(X,st_Y,test_size=0.2,random_state=40)\n",
    "lt_X_train,lt_X_test,lt_Y_train,lt_Y_test = train_test_split(X,lt_Y,test_size=0.2,random_state=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GKFb9XLbU7Xu"
   },
   "source": [
    "KNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KS3ws2M6MTmH",
    "outputId": "d4ec2089-c08b-4139-9102-e7e65579e96c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Spearman's correlation coefficient is: 0.237\n",
      "The Spearman's correlation coefficient is: 0.075\n"
     ]
    }
   ],
   "source": [
    "knnRegressor = KNeighborsRegressor(n_neighbors = 77)\n",
    "knnRegressor.fit(X_train, Y_train)\n",
    "y_pred = knnRegressor.predict(X_test)\n",
    "Get_score(y_pred, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8YPcq_x-h-Ra"
   },
   "source": [
    "Random Forest ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nVBO-_hd16fQ",
    "outputId": "331033e8-bf14-4acd-d57e-5fe6c1dbfa1e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 100\n",
      "building tree 3 of 100\n",
      "building tree 4 of 100\n",
      "building tree 5 of 100\n",
      "building tree 6 of 100\n",
      "building tree 7 of 100\n",
      "building tree 8 of 100\n",
      "building tree 9 of 100\n",
      "building tree 10 of 100\n",
      "building tree 11 of 100\n",
      "building tree 12 of 100\n",
      "building tree 13 of 100\n",
      "building tree 14 of 100\n",
      "building tree 15 of 100\n",
      "building tree 16 of 100\n",
      "building tree 17 of 100\n",
      "building tree 18 of 100\n",
      "building tree 19 of 100\n",
      "building tree 20 of 100\n",
      "building tree 21 of 100\n",
      "building tree 22 of 100\n",
      "building tree 23 of 100\n",
      "building tree 24 of 100\n",
      "building tree 25 of 100\n",
      "building tree 26 of 100\n",
      "building tree 27 of 100\n",
      "building tree 28 of 100\n",
      "building tree 29 of 100\n",
      "building tree 30 of 100\n",
      "building tree 31 of 100\n",
      "building tree 32 of 100\n",
      "building tree 33 of 100\n",
      "building tree 34 of 100\n",
      "building tree 35 of 100\n",
      "building tree 36 of 100\n",
      "building tree 37 of 100\n",
      "building tree 38 of 100\n",
      "building tree 39 of 100\n",
      "building tree 40 of 100\n",
      "building tree 41 of 100\n",
      "building tree 42 of 100\n",
      "building tree 43 of 100\n",
      "building tree 44 of 100\n",
      "building tree 45 of 100\n",
      "building tree 46 of 100\n",
      "building tree 47 of 100\n",
      "building tree 48 of 100\n",
      "building tree 49 of 100\n",
      "building tree 50 of 100\n",
      "building tree 51 of 100\n",
      "building tree 52 of 100\n",
      "building tree 53 of 100\n",
      "building tree 54 of 100\n",
      "building tree 55 of 100\n",
      "building tree 56 of 100\n",
      "building tree 57 of 100\n",
      "building tree 58 of 100\n",
      "building tree 59 of 100\n",
      "building tree 60 of 100\n",
      "building tree 61 of 100\n",
      "building tree 62 of 100\n",
      "building tree 63 of 100\n",
      "building tree 64 of 100\n",
      "building tree 65 of 100\n",
      "building tree 66 of 100\n",
      "building tree 67 of 100\n",
      "building tree 68 of 100\n",
      "building tree 69 of 100\n",
      "building tree 70 of 100\n",
      "building tree 71 of 100\n",
      "building tree 72 of 100\n",
      "building tree 73 of 100\n",
      "building tree 74 of 100\n",
      "building tree 75 of 100\n",
      "building tree 76 of 100\n",
      "building tree 77 of 100\n",
      "building tree 78 of 100\n",
      "building tree 79 of 100\n",
      "building tree 80 of 100\n",
      "building tree 81 of 100\n",
      "building tree 82 of 100\n",
      "building tree 83 of 100\n",
      "building tree 84 of 100\n",
      "building tree 85 of 100\n",
      "building tree 86 of 100\n",
      "building tree 87 of 100\n",
      "building tree 88 of 100\n",
      "building tree 89 of 100\n",
      "building tree 90 of 100\n",
      "building tree 91 of 100\n",
      "building tree 92 of 100\n",
      "building tree 93 of 100\n",
      "building tree 94 of 100\n",
      "building tree 95 of 100\n",
      "building tree 96 of 100\n",
      "building tree 97 of 100\n",
      "building tree 98 of 100\n",
      "building tree 99 of 100\n",
      "building tree 100 of 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
       "                      random_state=42, verbose=2, warm_start=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestRegressor(n_estimators=100,random_state=42,verbose=2)\n",
    "rf.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MggG0gjCp7Gn",
    "outputId": "ed893f3d-6feb-4fc9-8add-fbdf08cea2bd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "rf_pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RmZ0aRFBt3-3",
    "outputId": "01eece58-cc37-423d-e5d0-7491046ae146"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Spearman's correlation coefficient is: 0.247\n",
      "The Spearman's correlation coefficient is: 0.065\n"
     ]
    }
   ],
   "source": [
    "Get_score(rf_pred, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3FtNELuzGvJS"
   },
   "source": [
    "Building Neural Models from Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "y1WVodhKGBOV"
   },
   "outputs": [],
   "source": [
    "# add dropout - Helps prevent overfitting\n",
    "# add regularizers - Regularizers allow to apply penalties on layer parameters or layer activity during optimization.\n",
    "# activations - Used to determine the output of network. It maps the resulting values in between 0 to 1 or -1 to 1 etc. (depending upon the function).\n",
    "model = Sequential() # The Sequential model is a linear stack of layers.\n",
    "model.add(layers.Dense(10,activation='relu',kernel_regularizer=regularizers.l2(0.0005),input_shape=(178,))) # Just your regular densely-connected NN layer.\n",
    "model.add(layers.Dropout(0.5)) #Dropout consists in randomly setting a fraction rate of input units to 0 at each update during training; helps prevent overfitting.\n",
    "model.add(layers.Dense(10,activation='relu',kernel_regularizer=regularizers.l2(0.0005)))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(2,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9PgjymEkGWbu",
    "outputId": "6c3be2da-d02c-49cb-a2d3-54044f7518d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "150/150 [==============================] - 1s 1ms/step - loss: 0.1063 - accuracy: 0.5255\n",
      "Epoch 2/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0459 - accuracy: 0.5138\n",
      "Epoch 3/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0303 - accuracy: 0.5499\n",
      "Epoch 4/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0217 - accuracy: 0.6020\n",
      "Epoch 5/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0187 - accuracy: 0.6233\n",
      "Epoch 6/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0169 - accuracy: 0.6470\n",
      "Epoch 7/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0163 - accuracy: 0.6934\n",
      "Epoch 8/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0153 - accuracy: 0.6985\n",
      "Epoch 9/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0151 - accuracy: 0.7201\n",
      "Epoch 10/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0146 - accuracy: 0.6984\n",
      "Epoch 11/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0147 - accuracy: 0.6966\n",
      "Epoch 12/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0143 - accuracy: 0.7143\n",
      "Epoch 13/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0143 - accuracy: 0.6968\n",
      "Epoch 14/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0143 - accuracy: 0.6991\n",
      "Epoch 15/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0145 - accuracy: 0.7148\n",
      "Epoch 16/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0139 - accuracy: 0.7017\n",
      "Epoch 17/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0136 - accuracy: 0.6935\n",
      "Epoch 18/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0137 - accuracy: 0.7085\n",
      "Epoch 19/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0141 - accuracy: 0.7057\n",
      "Epoch 20/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0137 - accuracy: 0.7005\n",
      "The Spearman's correlation coefficient is: 0.090\n",
      "The Spearman's correlation coefficient is: 0.048\n"
     ]
    }
   ],
   "source": [
    "# compile the model \n",
    "model.compile(optimizer='rmsprop',loss='mse',metrics=['accuracy'])\n",
    "# training the model \n",
    "history = model.fit(X_train,Y_train,epochs=20)\n",
    "predictions = model.predict(X_test)\n",
    "Get_score(predictions, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MN21v180Lhwf"
   },
   "source": [
    "SVR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "Du5QiYnwKudL"
   },
   "outputs": [],
   "source": [
    "st_X = StandardScaler()\n",
    "st_Y = StandardScaler()\n",
    "st_X_train = st_X.fit_transform(st_X_train)\n",
    "st_Y_train = st_Y.fit_transform(st_Y_train)\n",
    "lt_X = StandardScaler()\n",
    "lt_Y = StandardScaler()\n",
    "lt_X_train = lt_X.fit_transform(lt_X_train)\n",
    "lt_Y_train = lt_Y.fit_transform(lt_Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GK5VkGYrK3B2",
    "outputId": "f0530b10-7263-4e06-e41e-ce7766ca8c1c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
       "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st_regressor = SVR(kernel = 'rbf')\n",
    "st_regressor.fit(st_X_train, st_Y_train)\n",
    "lt_regressor = SVR(kernel = 'rbf')\n",
    "lt_regressor.fit(lt_X_train,lt_Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "q-KN6670K-3w"
   },
   "outputs": [],
   "source": [
    "st_pred = st_regressor.predict(st_X_test)\n",
    "st_pred = st_Y.inverse_transform(st_pred)\n",
    "lt_pred = lt_regressor.predict(lt_X_test)\n",
    "lt_pred = lt_Y.inverse_transform(lt_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VsrSottfLDv2",
    "outputId": "fb7a2911-3445-43fd-fd74-9e0797f1cbd6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Spearman's correlation coefficient is: 0.199\n",
      "The Spearman's correlation coefficient is: 0.087\n"
     ]
    }
   ],
   "source": [
    "Get_score(st_pred, st_Y_test)\n",
    "Get_score(lt_pred, lt_Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ICfTnYo1Lk6x"
   },
   "source": [
    "XGBoost Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mwBmJCYGb8a3",
    "outputId": "227167a7-67b9-484f-8a4b-cac995639936"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:48:22] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[13:50:40] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "             importance_type='gain', learning_rate=0.01, loss='lad',\n",
       "             max_delta_step=0, max_depth=12, min_child_weight=1,\n",
       "             min_samples_split=2, missing=None, n_estimators=650, n_jobs=1,\n",
       "             nthread=None, objective='reg:linear', random_state=0, reg_alpha=0,\n",
       "             reg_lambda=1, scale_pos_weight=1, seed=None, silent=None,\n",
       "             subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 136,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "params = {'n_estimators':650, 'max_depth':12, 'min_samples_split':2, 'learning_rate':0.01, 'loss':'lad'}\n",
    "xgb_st = xgb.XGBRegressor(**params)\n",
    "xgb_lt = xgb.XGBRegressor(**params)\n",
    "xgb_st.fit(st_X_train, st_Y_train)\n",
    "xgb_lt.fit(lt_X_train, lt_Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6oxv-Xj3b8bN",
    "outputId": "8f37a914-08bf-4e1b-a4a2-72e21a3d8561"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Spearman's correlation coefficient is: 0.268\n",
      "The Spearman's correlation coefficient is: 0.073\n"
     ]
    }
   ],
   "source": [
    "Get_score(xgb_st.predict(st_X_test), st_Y_test)\n",
    "Get_score(xgb_lt.predict(lt_X_test), lt_Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kBH9XtjY5jlr"
   },
   "source": [
    "## Using LBP feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E2rVhqJ10h3W"
   },
   "source": [
    "Setting up the DV (Y) and IDVs (X) along with train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "id": "tzhNF3Sv0h3k"
   },
   "outputs": [],
   "source": [
    "Y = GT[['short-term_memorability','long-term_memorability']].values\n",
    "st_Y = GT[['short-term_memorability']].values\n",
    "lt_Y = GT[['long-term_memorability']].values\n",
    "X = LBP_seq \n",
    "X_train, X_test, Y_train, Y_test = train_test_split( X, Y, test_size=0.2, random_state = 42) \n",
    "st_X_train,st_X_test,st_Y_train,st_Y_test = train_test_split(X,st_Y,test_size=0.2,random_state=40)\n",
    "lt_X_train,lt_X_test,lt_Y_train,lt_Y_test = train_test_split(X,lt_Y,test_size=0.2,random_state=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nS4Ll7l90h3k"
   },
   "source": [
    "KNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5INKzYJ00h3l",
    "outputId": "8bc8ff41-cbdb-4370-9df3-fe0289a60a39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Spearman's correlation coefficient is: 0.230\n",
      "The Spearman's correlation coefficient is: 0.055\n"
     ]
    }
   ],
   "source": [
    "knnRegressor = KNeighborsRegressor(n_neighbors = 77)\n",
    "knnRegressor.fit(X_train, Y_train)\n",
    "y_pred = knnRegressor.predict(X_test)\n",
    "Get_score(y_pred, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lv5r0Bvk0h3m"
   },
   "source": [
    "Random Forest ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BQwhTjXb0h3m",
    "outputId": "9598d22f-320c-4427-8d33-f7f64942fd5f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 100\n",
      "building tree 3 of 100\n",
      "building tree 4 of 100\n",
      "building tree 5 of 100\n",
      "building tree 6 of 100\n",
      "building tree 7 of 100\n",
      "building tree 8 of 100\n",
      "building tree 9 of 100\n",
      "building tree 10 of 100\n",
      "building tree 11 of 100\n",
      "building tree 12 of 100\n",
      "building tree 13 of 100\n",
      "building tree 14 of 100\n",
      "building tree 15 of 100\n",
      "building tree 16 of 100\n",
      "building tree 17 of 100\n",
      "building tree 18 of 100\n",
      "building tree 19 of 100\n",
      "building tree 20 of 100\n",
      "building tree 21 of 100\n",
      "building tree 22 of 100\n",
      "building tree 23 of 100\n",
      "building tree 24 of 100\n",
      "building tree 25 of 100\n",
      "building tree 26 of 100\n",
      "building tree 27 of 100\n",
      "building tree 28 of 100\n",
      "building tree 29 of 100\n",
      "building tree 30 of 100\n",
      "building tree 31 of 100\n",
      "building tree 32 of 100\n",
      "building tree 33 of 100\n",
      "building tree 34 of 100\n",
      "building tree 35 of 100\n",
      "building tree 36 of 100\n",
      "building tree 37 of 100\n",
      "building tree 38 of 100\n",
      "building tree 39 of 100\n",
      "building tree 40 of 100\n",
      "building tree 41 of 100\n",
      "building tree 42 of 100\n",
      "building tree 43 of 100\n",
      "building tree 44 of 100\n",
      "building tree 45 of 100\n",
      "building tree 46 of 100\n",
      "building tree 47 of 100\n",
      "building tree 48 of 100\n",
      "building tree 49 of 100\n",
      "building tree 50 of 100\n",
      "building tree 51 of 100\n",
      "building tree 52 of 100\n",
      "building tree 53 of 100\n",
      "building tree 54 of 100\n",
      "building tree 55 of 100\n",
      "building tree 56 of 100\n",
      "building tree 57 of 100\n",
      "building tree 58 of 100\n",
      "building tree 59 of 100\n",
      "building tree 60 of 100\n",
      "building tree 61 of 100\n",
      "building tree 62 of 100\n",
      "building tree 63 of 100\n",
      "building tree 64 of 100\n",
      "building tree 65 of 100\n",
      "building tree 66 of 100\n",
      "building tree 67 of 100\n",
      "building tree 68 of 100\n",
      "building tree 69 of 100\n",
      "building tree 70 of 100\n",
      "building tree 71 of 100\n",
      "building tree 72 of 100\n",
      "building tree 73 of 100\n",
      "building tree 74 of 100\n",
      "building tree 75 of 100\n",
      "building tree 76 of 100\n",
      "building tree 77 of 100\n",
      "building tree 78 of 100\n",
      "building tree 79 of 100\n",
      "building tree 80 of 100\n",
      "building tree 81 of 100\n",
      "building tree 82 of 100\n",
      "building tree 83 of 100\n",
      "building tree 84 of 100\n",
      "building tree 85 of 100\n",
      "building tree 86 of 100\n",
      "building tree 87 of 100\n",
      "building tree 88 of 100\n",
      "building tree 89 of 100\n",
      "building tree 90 of 100\n",
      "building tree 91 of 100\n",
      "building tree 92 of 100\n",
      "building tree 93 of 100\n",
      "building tree 94 of 100\n",
      "building tree 95 of 100\n",
      "building tree 96 of 100\n",
      "building tree 97 of 100\n",
      "building tree 98 of 100\n",
      "building tree 99 of 100\n",
      "building tree 100 of 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:  2.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
       "                      random_state=42, verbose=2, warm_start=False)"
      ]
     },
     "execution_count": 73,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestRegressor(n_estimators=100,random_state=42,verbose=2)\n",
    "rf.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A_sy0PDI0h3m",
    "outputId": "3d24d313-6b7f-4f63-a046-23cd39e6448f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "rf_pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q-i1kEQy0h3n",
    "outputId": "bcb5e99e-f1e7-4960-9963-fc8753e48a47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Spearman's correlation coefficient is: 0.318\n",
      "The Spearman's correlation coefficient is: 0.057\n"
     ]
    }
   ],
   "source": [
    "Get_score(rf_pred, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z8SRdCnV0h3n"
   },
   "source": [
    "Building Neural Models from Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "oI60a_140h3n"
   },
   "outputs": [],
   "source": [
    "# add dropout - Helps prevent overfitting\n",
    "# add regularizers - Regularizers allow to apply penalties on layer parameters or layer activity during optimization.\n",
    "# activations - Used to determine the output of network. It maps the resulting values in between 0 to 1 or -1 to 1 etc. (depending upon the function).\n",
    "model = Sequential() # The Sequential model is a linear stack of layers.\n",
    "model.add(layers.Dense(10,activation='relu',kernel_regularizer=regularizers.l2(0.0005),input_shape=(366,))) # Just your regular densely-connected NN layer.\n",
    "model.add(layers.Dropout(0.5)) #Dropout consists in randomly setting a fraction rate of input units to 0 at each update during training; helps prevent overfitting.\n",
    "model.add(layers.Dense(10,activation='relu',kernel_regularizer=regularizers.l2(0.0005)))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(2,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nf-nDAGp0h3o",
    "outputId": "221cd279-5c8e-4c03-cde8-865bd59150cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "150/150 [==============================] - 1s 1ms/step - loss: 0.0990 - accuracy: 0.5958\n",
      "Epoch 2/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0397 - accuracy: 0.6162\n",
      "Epoch 3/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0254 - accuracy: 0.6611\n",
      "Epoch 4/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0198 - accuracy: 0.6766\n",
      "Epoch 5/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0173 - accuracy: 0.6981\n",
      "Epoch 6/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0158 - accuracy: 0.7053\n",
      "Epoch 7/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0159 - accuracy: 0.7020\n",
      "Epoch 8/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0156 - accuracy: 0.7062\n",
      "Epoch 9/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0146 - accuracy: 0.7009\n",
      "Epoch 10/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0148 - accuracy: 0.7123\n",
      "Epoch 11/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0148 - accuracy: 0.6888\n",
      "Epoch 12/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0147 - accuracy: 0.6928\n",
      "Epoch 13/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0143 - accuracy: 0.7110\n",
      "Epoch 14/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0138 - accuracy: 0.7078\n",
      "Epoch 15/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0142 - accuracy: 0.7015\n",
      "Epoch 16/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0139 - accuracy: 0.7043\n",
      "Epoch 17/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0142 - accuracy: 0.6900\n",
      "Epoch 18/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0133 - accuracy: 0.7043\n",
      "Epoch 19/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0137 - accuracy: 0.7100\n",
      "Epoch 20/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0138 - accuracy: 0.7017\n",
      "The Spearman's correlation coefficient is: 0.212\n",
      "The Spearman's correlation coefficient is: 0.068\n"
     ]
    }
   ],
   "source": [
    "# compile the model \n",
    "model.compile(optimizer='rmsprop',loss='mse',metrics=['accuracy'])\n",
    "# training the model \n",
    "history = model.fit(X_train,Y_train,epochs=20)\n",
    "predictions = model.predict(X_test)\n",
    "Get_score(predictions, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d9hHu6bP0h3o"
   },
   "source": [
    "SVR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "Jj1ICYnV0h3o"
   },
   "outputs": [],
   "source": [
    "st_X = StandardScaler()\n",
    "st_Y = StandardScaler()\n",
    "st_X_train = st_X.fit_transform(st_X_train)\n",
    "st_Y_train = st_Y.fit_transform(st_Y_train)\n",
    "lt_X = StandardScaler()\n",
    "lt_Y = StandardScaler()\n",
    "lt_X_train = lt_X.fit_transform(lt_X_train)\n",
    "lt_Y_train = lt_Y.fit_transform(lt_Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9yk7acUX0h3o",
    "outputId": "29a567a1-8b4c-4ed8-8940-6779f3c54cdc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
       "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 79,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st_regressor = SVR(kernel = 'rbf')\n",
    "st_regressor.fit(st_X_train, st_Y_train)\n",
    "lt_regressor = SVR(kernel = 'rbf')\n",
    "lt_regressor.fit(lt_X_train,lt_Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "J0vWWfZb0h3o"
   },
   "outputs": [],
   "source": [
    "st_pred = st_regressor.predict(st_X_test)\n",
    "st_pred = st_Y.inverse_transform(st_pred)\n",
    "lt_pred = lt_regressor.predict(lt_X_test)\n",
    "lt_pred = lt_Y.inverse_transform(lt_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d1Yp5qOW0h3o",
    "outputId": "e58d630f-b024-4641-8efc-20faf814f7ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Spearman's correlation coefficient is: -0.088\n",
      "The Spearman's correlation coefficient is: -0.040\n"
     ]
    }
   ],
   "source": [
    "Get_score(st_pred, st_Y_test)\n",
    "Get_score(lt_pred, lt_Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yO8IoojVeGEy"
   },
   "source": [
    "XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UU0vzunkeGFD",
    "outputId": "59aef751-c0dc-4b90-e7c3-ebfafe3fe10c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:58:20] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:02:45] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "             importance_type='gain', learning_rate=0.01, loss='lad',\n",
       "             max_delta_step=0, max_depth=12, min_child_weight=1,\n",
       "             min_samples_split=2, missing=None, n_estimators=650, n_jobs=1,\n",
       "             nthread=None, objective='reg:linear', random_state=0, reg_alpha=0,\n",
       "             reg_lambda=1, scale_pos_weight=1, seed=None, silent=None,\n",
       "             subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 140,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'n_estimators':650, 'max_depth':12, 'min_samples_split':2, 'learning_rate':0.01, 'loss':'lad'}\n",
    "xgb_st = xgb.XGBRegressor(**params)\n",
    "xgb_lt = xgb.XGBRegressor(**params)\n",
    "xgb_st.fit(st_X_train, st_Y_train)\n",
    "xgb_lt.fit(lt_X_train, lt_Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZIOQ6h4oeGFE",
    "outputId": "4d798276-3acb-4b28-bca9-674a0a0e5941"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Spearman's correlation coefficient is: 0.253\n",
      "The Spearman's correlation coefficient is: 0.051\n"
     ]
    }
   ],
   "source": [
    "Get_score(xgb_st.predict(st_X_test), st_Y_test)\n",
    "Get_score(xgb_lt.predict(lt_X_test), lt_Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nKxfR5i58KNk"
   },
   "source": [
    "## Using C3D & HMP feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TrI50ZuC8KOE"
   },
   "source": [
    "Setting up the DV (Y) and IDVs (X) along with train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "id": "Exd6U16d8KOG"
   },
   "outputs": [],
   "source": [
    "Y = GT[['short-term_memorability','long-term_memorability']].values\n",
    "st_Y = GT[['short-term_memorability']].values\n",
    "lt_Y = GT[['long-term_memorability']].values\n",
    "X = C3D_HMP \n",
    "X_train, X_test, Y_train, Y_test = train_test_split( X, Y, test_size=0.2, random_state = 42) \n",
    "st_X_train,st_X_test,st_Y_train,st_Y_test = train_test_split(X,st_Y,test_size=0.2,random_state=40)\n",
    "lt_X_train,lt_X_test,lt_Y_train,lt_Y_test = train_test_split(X,lt_Y,test_size=0.2,random_state=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sJM4Dp078KOH"
   },
   "source": [
    "KNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oVqnVYdy8KOI",
    "outputId": "828745ed-4a64-42a7-8271-5ea900a1de67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Spearman's correlation coefficient is: 0.255\n",
      "The Spearman's correlation coefficient is: 0.100\n"
     ]
    }
   ],
   "source": [
    "knnRegressor = KNeighborsRegressor(n_neighbors = 77)\n",
    "knnRegressor.fit(X_train, Y_train)\n",
    "y_pred = knnRegressor.predict(X_test)\n",
    "Get_score(y_pred, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HRL0UPyY8KOI"
   },
   "source": [
    "Random Forest ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UZcV56zE8KOJ",
    "outputId": "de0fc2a1-cb4e-4db0-a2c4-7f2ee485c116"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 100\n",
      "building tree 3 of 100\n",
      "building tree 4 of 100\n",
      "building tree 5 of 100\n",
      "building tree 6 of 100\n",
      "building tree 7 of 100\n",
      "building tree 8 of 100\n",
      "building tree 9 of 100\n",
      "building tree 10 of 100\n",
      "building tree 11 of 100\n",
      "building tree 12 of 100\n",
      "building tree 13 of 100\n",
      "building tree 14 of 100\n",
      "building tree 15 of 100\n",
      "building tree 16 of 100\n",
      "building tree 17 of 100\n",
      "building tree 18 of 100\n",
      "building tree 19 of 100\n",
      "building tree 20 of 100\n",
      "building tree 21 of 100\n",
      "building tree 22 of 100\n",
      "building tree 23 of 100\n",
      "building tree 24 of 100\n",
      "building tree 25 of 100\n",
      "building tree 26 of 100\n",
      "building tree 27 of 100\n",
      "building tree 28 of 100\n",
      "building tree 29 of 100\n",
      "building tree 30 of 100\n",
      "building tree 31 of 100\n",
      "building tree 32 of 100\n",
      "building tree 33 of 100\n",
      "building tree 34 of 100\n",
      "building tree 35 of 100\n",
      "building tree 36 of 100\n",
      "building tree 37 of 100\n",
      "building tree 38 of 100\n",
      "building tree 39 of 100\n",
      "building tree 40 of 100\n",
      "building tree 41 of 100\n",
      "building tree 42 of 100\n",
      "building tree 43 of 100\n",
      "building tree 44 of 100\n",
      "building tree 45 of 100\n",
      "building tree 46 of 100\n",
      "building tree 47 of 100\n",
      "building tree 48 of 100\n",
      "building tree 49 of 100\n",
      "building tree 50 of 100\n",
      "building tree 51 of 100\n",
      "building tree 52 of 100\n",
      "building tree 53 of 100\n",
      "building tree 54 of 100\n",
      "building tree 55 of 100\n",
      "building tree 56 of 100\n",
      "building tree 57 of 100\n",
      "building tree 58 of 100\n",
      "building tree 59 of 100\n",
      "building tree 60 of 100\n",
      "building tree 61 of 100\n",
      "building tree 62 of 100\n",
      "building tree 63 of 100\n",
      "building tree 64 of 100\n",
      "building tree 65 of 100\n",
      "building tree 66 of 100\n",
      "building tree 67 of 100\n",
      "building tree 68 of 100\n",
      "building tree 69 of 100\n",
      "building tree 70 of 100\n",
      "building tree 71 of 100\n",
      "building tree 72 of 100\n",
      "building tree 73 of 100\n",
      "building tree 74 of 100\n",
      "building tree 75 of 100\n",
      "building tree 76 of 100\n",
      "building tree 77 of 100\n",
      "building tree 78 of 100\n",
      "building tree 79 of 100\n",
      "building tree 80 of 100\n",
      "building tree 81 of 100\n",
      "building tree 82 of 100\n",
      "building tree 83 of 100\n",
      "building tree 84 of 100\n",
      "building tree 85 of 100\n",
      "building tree 86 of 100\n",
      "building tree 87 of 100\n",
      "building tree 88 of 100\n",
      "building tree 89 of 100\n",
      "building tree 90 of 100\n",
      "building tree 91 of 100\n",
      "building tree 92 of 100\n",
      "building tree 93 of 100\n",
      "building tree 94 of 100\n",
      "building tree 95 of 100\n",
      "building tree 96 of 100\n",
      "building tree 97 of 100\n",
      "building tree 98 of 100\n",
      "building tree 99 of 100\n",
      "building tree 100 of 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:  2.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
       "                      random_state=42, verbose=2, warm_start=False)"
      ]
     },
     "execution_count": 88,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestRegressor(n_estimators=100,random_state=42,verbose=2)\n",
    "rf.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kiA5kIoa8KOJ",
    "outputId": "e74ef5e6-c41e-4dc0-a4be-9b0b927422dd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "rf_pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vVyzFr8T8KOK",
    "outputId": "7e1c3005-7749-49dc-dcb0-4210a4c7a951"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Spearman's correlation coefficient is: 0.303\n",
      "The Spearman's correlation coefficient is: 0.123\n"
     ]
    }
   ],
   "source": [
    "Get_score(rf_pred, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jYiRx-JW8KOK"
   },
   "source": [
    "Building Neural Models from Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "7E0MXnXF8KOL"
   },
   "outputs": [],
   "source": [
    "# add dropout - Helps prevent overfitting\n",
    "# add regularizers - Regularizers allow to apply penalties on layer parameters or layer activity during optimization.\n",
    "# activations - Used to determine the output of network. It maps the resulting values in between 0 to 1 or -1 to 1 etc. (depending upon the function).\n",
    "model = Sequential() # The Sequential model is a linear stack of layers.\n",
    "model.add(layers.Dense(10,activation='relu',kernel_regularizer=regularizers.l2(0.0005),input_shape=(279,))) # Just your regular densely-connected NN layer.\n",
    "model.add(layers.Dropout(0.5)) #Dropout consists in randomly setting a fraction rate of input units to 0 at each update during training; helps prevent overfitting.\n",
    "model.add(layers.Dense(10,activation='relu',kernel_regularizer=regularizers.l2(0.0005)))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(2,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F2aYTOVH8KOL",
    "outputId": "b14f05ee-2a4f-48a1-90be-17d40eec5514"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "150/150 [==============================] - 1s 1ms/step - loss: 0.1021 - accuracy: 0.6649\n",
      "Epoch 2/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0370 - accuracy: 0.6504\n",
      "Epoch 3/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0247 - accuracy: 0.6678\n",
      "Epoch 4/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0195 - accuracy: 0.6928\n",
      "Epoch 5/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0179 - accuracy: 0.6868\n",
      "Epoch 6/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0169 - accuracy: 0.7012\n",
      "Epoch 7/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0154 - accuracy: 0.6932\n",
      "Epoch 8/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0152 - accuracy: 0.7047\n",
      "Epoch 9/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0149 - accuracy: 0.6998\n",
      "Epoch 10/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0146 - accuracy: 0.6938\n",
      "Epoch 11/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0147 - accuracy: 0.7056\n",
      "Epoch 12/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0146 - accuracy: 0.7074\n",
      "Epoch 13/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0142 - accuracy: 0.7026\n",
      "Epoch 14/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0139 - accuracy: 0.7081\n",
      "Epoch 15/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0137 - accuracy: 0.7042\n",
      "Epoch 16/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0137 - accuracy: 0.7068\n",
      "Epoch 17/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0142 - accuracy: 0.6900\n",
      "Epoch 18/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0142 - accuracy: 0.7164\n",
      "Epoch 19/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0139 - accuracy: 0.6997\n",
      "Epoch 20/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0136 - accuracy: 0.6886\n",
      "The Spearman's correlation coefficient is: 0.265\n",
      "The Spearman's correlation coefficient is: 0.118\n"
     ]
    }
   ],
   "source": [
    "# compile the model \n",
    "model.compile(optimizer='rmsprop',loss='mse',metrics=['accuracy'])\n",
    "# training the model \n",
    "history = model.fit(X_train,Y_train,epochs=20)\n",
    "predictions = model.predict(X_test)\n",
    "Get_score(predictions, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oLDmszoU8KOM"
   },
   "source": [
    "SVR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "-9u6t6UY8KOM"
   },
   "outputs": [],
   "source": [
    "st_X = StandardScaler()\n",
    "st_Y = StandardScaler()\n",
    "st_X_train = st_X.fit_transform(st_X_train)\n",
    "st_Y_train = st_Y.fit_transform(st_Y_train)\n",
    "lt_X = StandardScaler()\n",
    "lt_Y = StandardScaler()\n",
    "lt_X_train = lt_X.fit_transform(lt_X_train)\n",
    "lt_Y_train = lt_Y.fit_transform(lt_Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "knWKGI878KOM",
    "outputId": "e89cd68d-d7fd-4853-98a1-1d2e7df862cd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
       "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 96,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st_regressor = SVR(kernel = 'rbf')\n",
    "st_regressor.fit(st_X_train, st_Y_train)\n",
    "lt_regressor = SVR(kernel = 'rbf')\n",
    "lt_regressor.fit(lt_X_train,lt_Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "MjaEJhHX8KON"
   },
   "outputs": [],
   "source": [
    "st_pred = st_regressor.predict(st_X_test)\n",
    "st_pred = st_Y.inverse_transform(st_pred)\n",
    "lt_pred = lt_regressor.predict(lt_X_test)\n",
    "lt_pred = lt_Y.inverse_transform(lt_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CbGD3GJr8KON",
    "outputId": "3cfe537c-dc33-493a-e718-84b719cfbb31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Spearman's correlation coefficient is: 0.259\n",
      "The Spearman's correlation coefficient is: 0.137\n"
     ]
    }
   ],
   "source": [
    "Get_score(st_pred, st_Y_test)\n",
    "Get_score(lt_pred, lt_Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "165OBPblfVje"
   },
   "source": [
    "XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z-EHobKofVjk",
    "outputId": "a7d25a97-3ed1-4e20-bf86-8a87040649ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:08:23] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:11:46] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "             importance_type='gain', learning_rate=0.01, loss='lad',\n",
       "             max_delta_step=0, max_depth=12, min_child_weight=1,\n",
       "             min_samples_split=2, missing=None, n_estimators=650, n_jobs=1,\n",
       "             nthread=None, objective='reg:linear', random_state=0, reg_alpha=0,\n",
       "             reg_lambda=1, scale_pos_weight=1, seed=None, silent=None,\n",
       "             subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 143,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'n_estimators':650, 'max_depth':12, 'min_samples_split':2, 'learning_rate':0.01, 'loss':'lad'}\n",
    "xgb_st = xgb.XGBRegressor(**params)\n",
    "xgb_lt = xgb.XGBRegressor(**params)\n",
    "xgb_st.fit(st_X_train, st_Y_train)\n",
    "xgb_lt.fit(lt_X_train, lt_Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dgIrGOkbfVjl",
    "outputId": "39493014-5ac6-4aee-8810-83583a593931"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Spearman's correlation coefficient is: 0.313\n",
      "The Spearman's correlation coefficient is: 0.077\n"
     ]
    }
   ],
   "source": [
    "Get_score(xgb_st.predict(st_X_test), st_Y_test)\n",
    "Get_score(xgb_lt.predict(lt_X_test), lt_Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WAfdAInZ8lAf"
   },
   "source": [
    "## Using C3D & LBP feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K1BAbArO8lAg"
   },
   "source": [
    "Setting up the DV (Y) and IDVs (X) along with train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "id": "RYaGtvpE8lAg"
   },
   "outputs": [],
   "source": [
    "Y = GT[['short-term_memorability','long-term_memorability']].values\n",
    "st_Y = GT[['short-term_memorability']].values\n",
    "lt_Y = GT[['long-term_memorability']].values\n",
    "X = C3D_LBP \n",
    "X_train, X_test, Y_train, Y_test = train_test_split( X, Y, test_size=0.2, random_state = 42) \n",
    "st_X_train,st_X_test,st_Y_train,st_Y_test = train_test_split(X,st_Y,test_size=0.2,random_state=40)\n",
    "lt_X_train,lt_X_test,lt_Y_train,lt_Y_test = train_test_split(X,lt_Y,test_size=0.2,random_state=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1qFtpWcj8lAh"
   },
   "source": [
    "KNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zYQalmLu8lAi",
    "outputId": "ce16bb1e-1068-4eac-bc82-b00db97419f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Spearman's correlation coefficient is: 0.274\n",
      "The Spearman's correlation coefficient is: 0.104\n"
     ]
    }
   ],
   "source": [
    "knnRegressor = KNeighborsRegressor(n_neighbors = 77)\n",
    "knnRegressor.fit(X_train, Y_train)\n",
    "y_pred = knnRegressor.predict(X_test)\n",
    "Get_score(y_pred, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cvu6GoWY8lAj"
   },
   "source": [
    "Random Forest ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5Jsor5iC8lAj",
    "outputId": "4c7eb65b-9fe1-4746-b920-cb6c10c0c4fd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 100\n",
      "building tree 3 of 100\n",
      "building tree 4 of 100\n",
      "building tree 5 of 100\n",
      "building tree 6 of 100\n",
      "building tree 7 of 100\n",
      "building tree 8 of 100\n",
      "building tree 9 of 100\n",
      "building tree 10 of 100\n",
      "building tree 11 of 100\n",
      "building tree 12 of 100\n",
      "building tree 13 of 100\n",
      "building tree 14 of 100\n",
      "building tree 15 of 100\n",
      "building tree 16 of 100\n",
      "building tree 17 of 100\n",
      "building tree 18 of 100\n",
      "building tree 19 of 100\n",
      "building tree 20 of 100\n",
      "building tree 21 of 100\n",
      "building tree 22 of 100\n",
      "building tree 23 of 100\n",
      "building tree 24 of 100\n",
      "building tree 25 of 100\n",
      "building tree 26 of 100\n",
      "building tree 27 of 100\n",
      "building tree 28 of 100\n",
      "building tree 29 of 100\n",
      "building tree 30 of 100\n",
      "building tree 31 of 100\n",
      "building tree 32 of 100\n",
      "building tree 33 of 100\n",
      "building tree 34 of 100\n",
      "building tree 35 of 100\n",
      "building tree 36 of 100\n",
      "building tree 37 of 100\n",
      "building tree 38 of 100\n",
      "building tree 39 of 100\n",
      "building tree 40 of 100\n",
      "building tree 41 of 100\n",
      "building tree 42 of 100\n",
      "building tree 43 of 100\n",
      "building tree 44 of 100\n",
      "building tree 45 of 100\n",
      "building tree 46 of 100\n",
      "building tree 47 of 100\n",
      "building tree 48 of 100\n",
      "building tree 49 of 100\n",
      "building tree 50 of 100\n",
      "building tree 51 of 100\n",
      "building tree 52 of 100\n",
      "building tree 53 of 100\n",
      "building tree 54 of 100\n",
      "building tree 55 of 100\n",
      "building tree 56 of 100\n",
      "building tree 57 of 100\n",
      "building tree 58 of 100\n",
      "building tree 59 of 100\n",
      "building tree 60 of 100\n",
      "building tree 61 of 100\n",
      "building tree 62 of 100\n",
      "building tree 63 of 100\n",
      "building tree 64 of 100\n",
      "building tree 65 of 100\n",
      "building tree 66 of 100\n",
      "building tree 67 of 100\n",
      "building tree 68 of 100\n",
      "building tree 69 of 100\n",
      "building tree 70 of 100\n",
      "building tree 71 of 100\n",
      "building tree 72 of 100\n",
      "building tree 73 of 100\n",
      "building tree 74 of 100\n",
      "building tree 75 of 100\n",
      "building tree 76 of 100\n",
      "building tree 77 of 100\n",
      "building tree 78 of 100\n",
      "building tree 79 of 100\n",
      "building tree 80 of 100\n",
      "building tree 81 of 100\n",
      "building tree 82 of 100\n",
      "building tree 83 of 100\n",
      "building tree 84 of 100\n",
      "building tree 85 of 100\n",
      "building tree 86 of 100\n",
      "building tree 87 of 100\n",
      "building tree 88 of 100\n",
      "building tree 89 of 100\n",
      "building tree 90 of 100\n",
      "building tree 91 of 100\n",
      "building tree 92 of 100\n",
      "building tree 93 of 100\n",
      "building tree 94 of 100\n",
      "building tree 95 of 100\n",
      "building tree 96 of 100\n",
      "building tree 97 of 100\n",
      "building tree 98 of 100\n",
      "building tree 99 of 100\n",
      "building tree 100 of 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:  3.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
       "                      random_state=42, verbose=2, warm_start=False)"
      ]
     },
     "execution_count": 103,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestRegressor(n_estimators=100,random_state=42,verbose=2)\n",
    "rf.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j27y4UKi8lAk",
    "outputId": "44afce6d-1e37-4f16-948b-3949b5de409a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "rf_pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g52xzm3Z8lAl",
    "outputId": "a9cdb5a7-7cb9-441c-b4be-73fab2a4b18a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Spearman's correlation coefficient is: 0.333\n",
      "The Spearman's correlation coefficient is: 0.099\n"
     ]
    }
   ],
   "source": [
    "Get_score(rf_pred, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QgaCVZ9H8lAm"
   },
   "source": [
    "Building Neural Models from Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "id": "r0IXSXrq8lAm"
   },
   "outputs": [],
   "source": [
    "# add dropout - Helps prevent overfitting\n",
    "# add regularizers - Regularizers allow to apply penalties on layer parameters or layer activity during optimization.\n",
    "# activations - Used to determine the output of network. It maps the resulting values in between 0 to 1 or -1 to 1 etc. (depending upon the function).\n",
    "model = Sequential() # The Sequential model is a linear stack of layers.\n",
    "model.add(layers.Dense(10,activation='relu',kernel_regularizer=regularizers.l2(0.0005),input_shape=(467,))) # Just your regular densely-connected NN layer.\n",
    "model.add(layers.Dropout(0.5)) #Dropout consists in randomly setting a fraction rate of input units to 0 at each update during training; helps prevent overfitting.\n",
    "model.add(layers.Dense(10,activation='relu',kernel_regularizer=regularizers.l2(0.0005)))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(2,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oaChdIjB8lAn",
    "outputId": "322fd076-d97f-495d-db09-c6ef6e22012b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "150/150 [==============================] - 1s 1ms/step - loss: 0.0938 - accuracy: 0.5997\n",
      "Epoch 2/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0392 - accuracy: 0.6171\n",
      "Epoch 3/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0269 - accuracy: 0.6396\n",
      "Epoch 4/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0221 - accuracy: 0.6547\n",
      "Epoch 5/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0187 - accuracy: 0.6816\n",
      "Epoch 6/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0175 - accuracy: 0.6798\n",
      "Epoch 7/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0161 - accuracy: 0.7024\n",
      "Epoch 8/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0154 - accuracy: 0.7115\n",
      "Epoch 9/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0149 - accuracy: 0.7120\n",
      "Epoch 10/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0143 - accuracy: 0.7105\n",
      "Epoch 11/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0151 - accuracy: 0.6928\n",
      "Epoch 12/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0144 - accuracy: 0.7067\n",
      "Epoch 13/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0137 - accuracy: 0.7156\n",
      "Epoch 14/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0138 - accuracy: 0.7023\n",
      "Epoch 15/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0142 - accuracy: 0.6954\n",
      "Epoch 16/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0139 - accuracy: 0.7102\n",
      "Epoch 17/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0138 - accuracy: 0.7167\n",
      "Epoch 18/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0137 - accuracy: 0.7066\n",
      "Epoch 19/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0134 - accuracy: 0.7037\n",
      "Epoch 20/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0135 - accuracy: 0.7216\n",
      "The Spearman's correlation coefficient is: 0.285\n",
      "The Spearman's correlation coefficient is: 0.112\n"
     ]
    }
   ],
   "source": [
    "# compile the model \n",
    "model.compile(optimizer='rmsprop',loss='mse',metrics=['accuracy'])\n",
    "# training the model \n",
    "history = model.fit(X_train,Y_train,epochs=20)\n",
    "predictions = model.predict(X_test)\n",
    "Get_score(predictions, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JeAUtVzL8lAn"
   },
   "source": [
    "SVR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "id": "ig0q1oe88lAo"
   },
   "outputs": [],
   "source": [
    "st_X = StandardScaler()\n",
    "st_Y = StandardScaler()\n",
    "st_X_train = st_X.fit_transform(st_X_train)\n",
    "st_Y_train = st_Y.fit_transform(st_Y_train)\n",
    "lt_X = StandardScaler()\n",
    "lt_Y = StandardScaler()\n",
    "lt_X_train = lt_X.fit_transform(lt_X_train)\n",
    "lt_Y_train = lt_Y.fit_transform(lt_Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qGWn8Aup8lAo",
    "outputId": "30df80dc-3051-48f4-c28c-34a2fd7b449a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
       "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 109,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st_regressor = SVR(kernel = 'rbf')\n",
    "st_regressor.fit(st_X_train, st_Y_train)\n",
    "lt_regressor = SVR(kernel = 'rbf')\n",
    "lt_regressor.fit(lt_X_train,lt_Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "id": "8NzXiD9x8lAp"
   },
   "outputs": [],
   "source": [
    "st_pred = st_regressor.predict(st_X_test)\n",
    "st_pred = st_Y.inverse_transform(st_pred)\n",
    "lt_pred = lt_regressor.predict(lt_X_test)\n",
    "lt_pred = lt_Y.inverse_transform(lt_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-n5Jeygr8lAq",
    "outputId": "a87af115-acf0-406c-fe97-5909dc580127"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Spearman's correlation coefficient is: 0.228\n",
      "The Spearman's correlation coefficient is: 0.094\n"
     ]
    }
   ],
   "source": [
    "Get_score(st_pred, st_Y_test)\n",
    "Get_score(lt_pred, lt_Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MwrD7dnFfahf"
   },
   "source": [
    "XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RPJjtzR4fahg",
    "outputId": "2d2834ee-616b-4d43-ace9-f97de708277f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:22:21] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:27:52] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "             importance_type='gain', learning_rate=0.01, loss='lad',\n",
       "             max_delta_step=0, max_depth=12, min_child_weight=1,\n",
       "             min_samples_split=2, missing=None, n_estimators=650, n_jobs=1,\n",
       "             nthread=None, objective='reg:linear', random_state=0, reg_alpha=0,\n",
       "             reg_lambda=1, scale_pos_weight=1, seed=None, silent=None,\n",
       "             subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 146,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'n_estimators':650, 'max_depth':12, 'min_samples_split':2, 'learning_rate':0.01, 'loss':'lad'}\n",
    "xgb_st = xgb.XGBRegressor(**params)\n",
    "xgb_lt = xgb.XGBRegressor(**params)\n",
    "xgb_st.fit(st_X_train, st_Y_train)\n",
    "xgb_lt.fit(lt_X_train, lt_Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o3gCPe52fahg",
    "outputId": "50796b19-9ac5-4aca-db88-bcedbe07ce71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Spearman's correlation coefficient is: 0.324\n",
      "The Spearman's correlation coefficient is: 0.095\n"
     ]
    }
   ],
   "source": [
    "Get_score(xgb_st.predict(st_X_test), st_Y_test)\n",
    "Get_score(xgb_lt.predict(lt_X_test), lt_Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p8_eu5ct8vYq"
   },
   "source": [
    "## Using C3D, HMP & LBP feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MZyl0h9A8vYr"
   },
   "source": [
    "Setting up the DV (Y) and IDVs (X) along with train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "id": "MqWrIGZi8vYr"
   },
   "outputs": [],
   "source": [
    "Y = GT[['short-term_memorability','long-term_memorability']].values\n",
    "st_Y = GT[['short-term_memorability']].values\n",
    "lt_Y = GT[['long-term_memorability']].values\n",
    "X = C3D_LBP_HMP\n",
    "X_train, X_test, Y_train, Y_test = train_test_split( X, Y, test_size=0.2, random_state = 42) \n",
    "st_X_train,st_X_test,st_Y_train,st_Y_test = train_test_split(X,st_Y,test_size=0.2,random_state=40)\n",
    "lt_X_train,lt_X_test,lt_Y_train,lt_Y_test = train_test_split(X,lt_Y,test_size=0.2,random_state=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OPGaROnc8vYr"
   },
   "source": [
    "KNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sbGryzkS8vYs",
    "outputId": "6a17474f-3879-416f-ed08-76f83f31ae0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Spearman's correlation coefficient is: 0.277\n",
      "The Spearman's correlation coefficient is: 0.101\n"
     ]
    }
   ],
   "source": [
    "knnRegressor = KNeighborsRegressor(n_neighbors = 77)\n",
    "knnRegressor.fit(X_train, Y_train)\n",
    "y_pred = knnRegressor.predict(X_test)\n",
    "Get_score(y_pred, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ttLTPHEF8vYs"
   },
   "source": [
    "Random Forest ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "POo6NxV78vYt",
    "outputId": "d9ccf33e-1163-4082-f534-d3ede6adc4fe"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 100\n",
      "building tree 3 of 100\n",
      "building tree 4 of 100\n",
      "building tree 5 of 100\n",
      "building tree 6 of 100\n",
      "building tree 7 of 100\n",
      "building tree 8 of 100\n",
      "building tree 9 of 100\n",
      "building tree 10 of 100\n",
      "building tree 11 of 100\n",
      "building tree 12 of 100\n",
      "building tree 13 of 100\n",
      "building tree 14 of 100\n",
      "building tree 15 of 100\n",
      "building tree 16 of 100\n",
      "building tree 17 of 100\n",
      "building tree 18 of 100\n",
      "building tree 19 of 100\n",
      "building tree 20 of 100\n",
      "building tree 21 of 100\n",
      "building tree 22 of 100\n",
      "building tree 23 of 100\n",
      "building tree 24 of 100\n",
      "building tree 25 of 100\n",
      "building tree 26 of 100\n",
      "building tree 27 of 100\n",
      "building tree 28 of 100\n",
      "building tree 29 of 100\n",
      "building tree 30 of 100\n",
      "building tree 31 of 100\n",
      "building tree 32 of 100\n",
      "building tree 33 of 100\n",
      "building tree 34 of 100\n",
      "building tree 35 of 100\n",
      "building tree 36 of 100\n",
      "building tree 37 of 100\n",
      "building tree 38 of 100\n",
      "building tree 39 of 100\n",
      "building tree 40 of 100\n",
      "building tree 41 of 100\n",
      "building tree 42 of 100\n",
      "building tree 43 of 100\n",
      "building tree 44 of 100\n",
      "building tree 45 of 100\n",
      "building tree 46 of 100\n",
      "building tree 47 of 100\n",
      "building tree 48 of 100\n",
      "building tree 49 of 100\n",
      "building tree 50 of 100\n",
      "building tree 51 of 100\n",
      "building tree 52 of 100\n",
      "building tree 53 of 100\n",
      "building tree 54 of 100\n",
      "building tree 55 of 100\n",
      "building tree 56 of 100\n",
      "building tree 57 of 100\n",
      "building tree 58 of 100\n",
      "building tree 59 of 100\n",
      "building tree 60 of 100\n",
      "building tree 61 of 100\n",
      "building tree 62 of 100\n",
      "building tree 63 of 100\n",
      "building tree 64 of 100\n",
      "building tree 65 of 100\n",
      "building tree 66 of 100\n",
      "building tree 67 of 100\n",
      "building tree 68 of 100\n",
      "building tree 69 of 100\n",
      "building tree 70 of 100\n",
      "building tree 71 of 100\n",
      "building tree 72 of 100\n",
      "building tree 73 of 100\n",
      "building tree 74 of 100\n",
      "building tree 75 of 100\n",
      "building tree 76 of 100\n",
      "building tree 77 of 100\n",
      "building tree 78 of 100\n",
      "building tree 79 of 100\n",
      "building tree 80 of 100\n",
      "building tree 81 of 100\n",
      "building tree 82 of 100\n",
      "building tree 83 of 100\n",
      "building tree 84 of 100\n",
      "building tree 85 of 100\n",
      "building tree 86 of 100\n",
      "building tree 87 of 100\n",
      "building tree 88 of 100\n",
      "building tree 89 of 100\n",
      "building tree 90 of 100\n",
      "building tree 91 of 100\n",
      "building tree 92 of 100\n",
      "building tree 93 of 100\n",
      "building tree 94 of 100\n",
      "building tree 95 of 100\n",
      "building tree 96 of 100\n",
      "building tree 97 of 100\n",
      "building tree 98 of 100\n",
      "building tree 99 of 100\n",
      "building tree 100 of 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:  4.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
       "                      random_state=42, verbose=2, warm_start=False)"
      ]
     },
     "execution_count": 116,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestRegressor(n_estimators=100,random_state=42,verbose=2)\n",
    "rf.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "prVIkGm48vYt",
    "outputId": "0bfd953b-4cf3-4f0d-c1c6-c052016bff45"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "rf_pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QRKGYKag8vYt",
    "outputId": "8c74997e-0627-4047-9c05-e0507cd229b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Spearman's correlation coefficient is: 0.348\n",
      "The Spearman's correlation coefficient is: 0.095\n"
     ]
    }
   ],
   "source": [
    "Get_score(rf_pred, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y-nEET6D8vYu"
   },
   "source": [
    "Building Neural Models from Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "id": "YPZNpPtL8vYu"
   },
   "outputs": [],
   "source": [
    "# add dropout - Helps prevent overfitting\n",
    "# add regularizers - Regularizers allow to apply penalties on layer parameters or layer activity during optimization.\n",
    "# activations - Used to determine the output of network. It maps the resulting values in between 0 to 1 or -1 to 1 etc. (depending upon the function).\n",
    "model = Sequential() # The Sequential model is a linear stack of layers.\n",
    "model.add(layers.Dense(10,activation='relu',kernel_regularizer=regularizers.l2(0.0005),input_shape=(645,))) # Just your regular densely-connected NN layer.\n",
    "model.add(layers.Dropout(0.5)) #Dropout consists in randomly setting a fraction rate of input units to 0 at each update during training; helps prevent overfitting.\n",
    "model.add(layers.Dense(10,activation='relu',kernel_regularizer=regularizers.l2(0.0005)))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(2,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cJWaepv98vYu",
    "outputId": "e33518f9-6480-44eb-f60a-5f9672eb6a7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "150/150 [==============================] - 1s 1ms/step - loss: 0.1063 - accuracy: 0.5049\n",
      "Epoch 2/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0563 - accuracy: 0.5314\n",
      "Epoch 3/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0362 - accuracy: 0.5387\n",
      "Epoch 4/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0252 - accuracy: 0.5752\n",
      "Epoch 5/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0204 - accuracy: 0.6257\n",
      "Epoch 6/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0177 - accuracy: 0.6801\n",
      "Epoch 7/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0159 - accuracy: 0.7115\n",
      "Epoch 8/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0154 - accuracy: 0.7067\n",
      "Epoch 9/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0148 - accuracy: 0.6986\n",
      "Epoch 10/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0145 - accuracy: 0.7057\n",
      "Epoch 11/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0149 - accuracy: 0.7079\n",
      "Epoch 12/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0144 - accuracy: 0.7142\n",
      "Epoch 13/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0139 - accuracy: 0.7022\n",
      "Epoch 14/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0140 - accuracy: 0.7013\n",
      "Epoch 15/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0135 - accuracy: 0.7090\n",
      "Epoch 16/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0138 - accuracy: 0.6915\n",
      "Epoch 17/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0138 - accuracy: 0.7010\n",
      "Epoch 18/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0141 - accuracy: 0.6994\n",
      "Epoch 19/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0139 - accuracy: 0.6959\n",
      "Epoch 20/20\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0140 - accuracy: 0.6984\n",
      "The Spearman's correlation coefficient is: 0.279\n",
      "The Spearman's correlation coefficient is: 0.105\n"
     ]
    }
   ],
   "source": [
    "# compile the model \n",
    "model.compile(optimizer='rmsprop',loss='mse',metrics=['accuracy'])\n",
    "# training the model \n",
    "history = model.fit(X_train,Y_train,epochs=20)\n",
    "predictions = model.predict(X_test)\n",
    "Get_score(predictions, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UynKJ4G08vYv"
   },
   "source": [
    "SVR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "id": "gyi9CuBj8vYv"
   },
   "outputs": [],
   "source": [
    "st_X = StandardScaler()\n",
    "st_Y = StandardScaler()\n",
    "st_X_train = st_X.fit_transform(st_X_train)\n",
    "st_Y_train = st_Y.fit_transform(st_Y_train)\n",
    "lt_X = StandardScaler()\n",
    "lt_Y = StandardScaler()\n",
    "lt_X_train = lt_X.fit_transform(lt_X_train)\n",
    "lt_Y_train = lt_Y.fit_transform(lt_Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JNUrAklG8vYv",
    "outputId": "abb9b3af-35f2-4a08-e729-a08d13356e7e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
       "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st_regressor = SVR(kernel = 'rbf')\n",
    "st_regressor.fit(st_X_train, st_Y_train)\n",
    "lt_regressor = SVR(kernel = 'rbf')\n",
    "lt_regressor.fit(lt_X_train,lt_Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "id": "0IGb90J68vYw"
   },
   "outputs": [],
   "source": [
    "st_pred = st_regressor.predict(st_X_test)\n",
    "st_pred = st_Y.inverse_transform(st_pred)\n",
    "lt_pred = lt_regressor.predict(lt_X_test)\n",
    "lt_pred = lt_Y.inverse_transform(lt_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8CvfPaJy8vYw",
    "outputId": "b21d149f-0128-4240-bcbb-041580f1fb11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Spearman's correlation coefficient is: 0.242\n",
      "The Spearman's correlation coefficient is: 0.099\n"
     ]
    }
   ],
   "source": [
    "Get_score(st_pred, st_Y_test)\n",
    "Get_score(lt_pred, lt_Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bqbI4PHRfdhu"
   },
   "source": [
    "XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uRKA73BBfdhw",
    "outputId": "9e6005d7-ad4c-4aeb-90be-5a27eec35d36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:40:33] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:48:05] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "             importance_type='gain', learning_rate=0.01, loss='lad',\n",
       "             max_delta_step=0, max_depth=12, min_child_weight=1,\n",
       "             min_samples_split=2, missing=None, n_estimators=650, n_jobs=1,\n",
       "             nthread=None, objective='reg:linear', random_state=0, reg_alpha=0,\n",
       "             reg_lambda=1, scale_pos_weight=1, seed=None, silent=None,\n",
       "             subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 149,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'n_estimators':650, 'max_depth':12, 'min_samples_split':2, 'learning_rate':0.01, 'loss':'lad'}\n",
    "xgb_st = xgb.XGBRegressor(**params)\n",
    "xgb_lt = xgb.XGBRegressor(**params)\n",
    "xgb_st.fit(st_X_train, st_Y_train)\n",
    "xgb_lt.fit(lt_X_train, lt_Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VOxpDnMlfdhx",
    "outputId": "4a293bf8-694a-4a63-a7f4-c3040e9894b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Spearman's correlation coefficient is: 0.337\n",
      "The Spearman's correlation coefficient is: 0.087\n"
     ]
    }
   ],
   "source": [
    "Get_score(xgb_st.predict(st_X_test), st_Y_test)\n",
    "Get_score(xgb_lt.predict(lt_X_test), lt_Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0wXlbcTp16r8"
   },
   "source": [
    "##Using the best performed model over the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3KkA7WQf-6QY"
   },
   "source": [
    "Loading the ground truth file from the Dev set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "id": "bPJxGbnM-6Qj"
   },
   "outputs": [],
   "source": [
    "# load the ground truth template\n",
    "GT_t = pd.read_csv('./Test-set/Ground-truth_test/ground_truth_template.csv')\n",
    "vid = GT_t.video.values  # list the video filenames from the ground truth template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "AB0uly0k_dR3",
    "outputId": "a16fa44c-649b-4bb8-bb24-9b47acf47ab0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video</th>\n",
       "      <th>short-term_memorability</th>\n",
       "      <th>nb_short-term_annotations</th>\n",
       "      <th>long-term_memorability</th>\n",
       "      <th>nb_long-term_annotations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7494</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7495</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7496</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7497</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7498</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   video  ...  nb_long-term_annotations\n",
       "0   7494  ...                        12\n",
       "1   7495  ...                        10\n",
       "2   7496  ...                        13\n",
       "3   7497  ...                        10\n",
       "4   7498  ...                        10\n",
       "\n",
       "[5 rows x 5 columns]"
      ]
     },
     "execution_count": 159,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GT_t.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0NyGa4M18guq"
   },
   "source": [
    "Loading the features from test set into a python dataframe from the drive (one time load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dRVuH1p_8gur",
    "outputId": "82a33ed0-1edc-4a45-daae-2a33d8e217ca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 2)"
      ]
     },
     "execution_count": 173,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting the C3D test feature\n",
    "c3d_features_t = pd.DataFrame(columns=['video','C3D'])\n",
    "for i in range(2000):\n",
    "  c3d_features_t = c3d_features_t.append({'video': vid[i], 'C3D': read_C3D('./Test-set/C3D_test/video' + str(vid[i]) + '.txt')}, ignore_index=True)\n",
    "c3d_features_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qH3xl2qY8gu1",
    "outputId": "9b2145ae-858b-4eab-cf33-345f41edfee4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 2)"
      ]
     },
     "execution_count": 178,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting the HMP test feature\n",
    "hmp_features_t = pd.DataFrame(columns=['video','HMP'])\n",
    "for i in range(2000):\n",
    "  hmp_features_t = hmp_features_t.append({'video': vid[i], 'HMP': read_HMP('./Test-set/HMP_test/video' + str(vid[i]) + '.txt')}, ignore_index=True)\n",
    "hmp_features_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wq0FRZo58gu1",
    "outputId": "a5101751-c945-4064-f43e-5d83920f354c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 2)"
      ]
     },
     "execution_count": 202,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting the LBP test feature\n",
    "lbp_features1_t = pd.DataFrame(columns=['video','LBP'])\n",
    "lbp_features2_t = pd.DataFrame(columns=['video','LBP'])\n",
    "lbp_features3_t = pd.DataFrame(columns=['video','LBP'])\n",
    "for i in range(2000):\n",
    "  lbp_features1_t = lbp_features1_t.append({'video': vid[i], 'LBP': read_LBP('./Test-set/LBP_test/video' + str(vid[i]) + '-0.txt')}, ignore_index=True)\n",
    "  lbp_features2_t = lbp_features2_t.append({'video': vid[i], 'LBP': read_LBP('./Test-set/LBP_test/video' + str(vid[i]) + '-56.txt')}, ignore_index=True)\n",
    "  lbp_features3_t = lbp_features3_t.append({'video': vid[i], 'LBP': read_LBP('./Test-set/LBP_test/video' + str(vid[i]) + '-112.txt')}, ignore_index=True)\n",
    "lbp_features1_t.shape\n",
    "lbp_features2_t.shape\n",
    "lbp_features3_t.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JWkWiDbY9db6"
   },
   "source": [
    "Saving and Loading the extracted features using the pickle files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YS-3DKH_9dcE"
   },
   "outputs": [],
   "source": [
    "#----------- Saving the test features to the drive ------------\n",
    "\n",
    "os.chdir('/content/drive/MyDrive')\n",
    "# Saving the C3D feature in Google Drive to reuse later  \n",
    "c3d_features_t.to_pickle('./C3D_Features_t.pickle')\n",
    "# Saving the HMP feature in Google Drive to reuse later  \n",
    "hmp_features_t.to_pickle('./HMP_Features_t.pickle')\n",
    "# Saving the LBP 0 frame feature in Google Drive to reuse later  \n",
    "lbp_features1_t.to_pickle('./LBP_0Frame_Features_t.pickle')\n",
    "# Saving the LBP 56 frame feature in Google Drive to reuse later  \n",
    "lbp_features2_t.to_pickle('./LBP_56Frame_Features_t.pickle')\n",
    "# Saving the LBP 112 frame feature in Google Drive to reuse later  \n",
    "lbp_features3_t.to_pickle('./LBP_112Frame_Features_t.pickle')\n",
    "# Changing the working directory\n",
    "os.chdir('/content/drive/MyDrive/CA684_Assignment/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IHAXGYXx9dcF"
   },
   "outputs": [],
   "source": [
    "#----------- Loading the test features from the drive ------------\n",
    "\n",
    "os.chdir('/content/drive/MyDrive')\n",
    "# Load C3D feature back in memory session\n",
    "c3d_features_t = pd.read_pickle('./C3D_Features_t.pickle')\n",
    "# Load HMP feature back in memory session\n",
    "hmp_features_t = pd.read_pickle('./HMP_Features_t.pickle')\n",
    "# Load LBP frame features back in memory session\n",
    "lbp_0frame_features_t = pd.read_pickle('./LBP_0Frame_Features_t.pickle')\n",
    "lbp_56frame_features_t = pd.read_pickle('./LBP_56Frame_Features_t.pickle')\n",
    "lbp_112frame_features_t = pd.read_pickle('./LBP_112Frame_Features_t.pickle')\n",
    "# Changing the working directory\n",
    "os.chdir('/content/drive/MyDrive/CA684_Assignment/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f8d9wXrXdK6v"
   },
   "source": [
    "Extracting the values of features from 1-D numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SYzvJEvZdK60",
    "outputId": "7209df78-9548-456b-8668-01c40dfd3a8c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 101)"
      ]
     },
     "execution_count": 193,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# C3D feature value extracted\n",
    "sequences = c3d_features_t['C3D']\n",
    "C3D_seq_t = np.zeros((len(sequences),len(c3d_features_t.loc[0,'C3D'])))\n",
    "for i in range(len(sequences)):\n",
    "    n = len(sequences[i])\n",
    "    C3D_seq_t[i,-n:] = sequences[i]\n",
    "C3D_seq_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "plAZm42rdK61",
    "outputId": "1aa84e16-30f4-4cf6-d480-a2c115a3f0e0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 6075)"
      ]
     },
     "execution_count": 194,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# HMP feature value extracted\n",
    "sequences = hmp_features_t['HMP']\n",
    "HMP_seq_t = np.zeros((len(sequences),len(hmp_features_t.loc[0,'HMP'])))\n",
    "for i in range(len(sequences)):\n",
    "    n = len(sequences[i])\n",
    "    HMP_seq_t[i,-n:] = sequences[i]\n",
    "HMP_seq_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BNWg-EKadK62",
    "outputId": "88e423f2-6cce-4dcb-aba3-f6a326b705b5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 366)"
      ]
     },
     "execution_count": 209,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LBP feature value extracted\n",
    "LBP_seq_t = np.concatenate((LBP_Frame(lbp_0frame_features_t),LBP_Frame(lbp_56frame_features_t),LBP_Frame(lbp_112frame_features_t)),axis = 1)\n",
    "LBP_seq_t.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M_vYff1jdK62"
   },
   "source": [
    "PCA technique to reduce the dimensionality of HMP feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wEz3p0wrdK63",
    "outputId": "4f9e5582-1a35-443e-a54a-39958bab9736"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 178)"
      ]
     },
     "execution_count": 222,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "# preserving the 99.9% of the variance i.e. reduced components explains 99.9% variance of the data \n",
    "pca = PCA(n_components=178)\n",
    "HMP_seq_PCA_t = pd.DataFrame(pca.fit_transform(HMP_seq_t))\n",
    "HMP_seq_PCA_t.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rxC3fBR1dK63"
   },
   "source": [
    "Merging the feature set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fKm4WvSHdK64",
    "outputId": "3d7be330-66ba-4a6c-dbca-b5f6c0520d0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 279)\n",
      "(2000, 467)\n",
      "(2000, 645)\n"
     ]
    }
   ],
   "source": [
    "# merging the C3D and reduced HMP feature set\n",
    "C3D_HMP_t = np.concatenate((C3D_seq_t,HMP_seq_PCA_t), axis = 1)\n",
    "\n",
    "# merging the C3D and LBP feature set\n",
    "C3D_LBP_t = np.concatenate((C3D_seq_t,LBP_seq_t), axis = 1)\n",
    "\n",
    "# merging the C3D, LBP and reduced HMP feature set\n",
    "C3D_LBP_HMP_t = np.concatenate((C3D_seq_t,LBP_seq_t,HMP_seq_PCA_t), axis = 1)\n",
    "\n",
    "print(C3D_HMP_t.shape)\n",
    "print(C3D_LBP_t.shape)\n",
    "print(C3D_LBP_HMP_t.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oBQR6oWtl9O1"
   },
   "source": [
    "Applying the best performing models to 6000 video training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "id": "TvcAURa1l9O2"
   },
   "outputs": [],
   "source": [
    "# Setting up the DV (Y) and IDVs (X) along with train test split\n",
    "\n",
    "st_Y = GT[['short-term_memorability']].values\n",
    "lt_Y = GT[['long-term_memorability']].values\n",
    "\n",
    "# short-term values\n",
    "st_X_train = C3D_LBP_HMP\n",
    "st_X_test = C3D_LBP_HMP_t\n",
    "st_Y_train = st_Y\n",
    "\n",
    "# long-term values\n",
    "lt_X_train = C3D_HMP\n",
    "lt_X_test = C3D_HMP_t\n",
    "lt_Y_train = lt_Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mLQ52X6HoLqn",
    "outputId": "0b732511-e42d-4cca-e450-a8fa9fe6fa40"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 100\n",
      "building tree 3 of 100\n",
      "building tree 4 of 100\n",
      "building tree 5 of 100\n",
      "building tree 6 of 100\n",
      "building tree 7 of 100\n",
      "building tree 8 of 100\n",
      "building tree 9 of 100\n",
      "building tree 10 of 100\n",
      "building tree 11 of 100\n",
      "building tree 12 of 100\n",
      "building tree 13 of 100\n",
      "building tree 14 of 100\n",
      "building tree 15 of 100\n",
      "building tree 16 of 100\n",
      "building tree 17 of 100\n",
      "building tree 18 of 100\n",
      "building tree 19 of 100\n",
      "building tree 20 of 100\n",
      "building tree 21 of 100\n",
      "building tree 22 of 100\n",
      "building tree 23 of 100\n",
      "building tree 24 of 100\n",
      "building tree 25 of 100\n",
      "building tree 26 of 100\n",
      "building tree 27 of 100\n",
      "building tree 28 of 100\n",
      "building tree 29 of 100\n",
      "building tree 30 of 100\n",
      "building tree 31 of 100\n",
      "building tree 32 of 100\n",
      "building tree 33 of 100\n",
      "building tree 34 of 100\n",
      "building tree 35 of 100\n",
      "building tree 36 of 100\n",
      "building tree 37 of 100\n",
      "building tree 38 of 100\n",
      "building tree 39 of 100\n",
      "building tree 40 of 100\n",
      "building tree 41 of 100\n",
      "building tree 42 of 100\n",
      "building tree 43 of 100\n",
      "building tree 44 of 100\n",
      "building tree 45 of 100\n",
      "building tree 46 of 100\n",
      "building tree 47 of 100\n",
      "building tree 48 of 100\n",
      "building tree 49 of 100\n",
      "building tree 50 of 100\n",
      "building tree 51 of 100\n",
      "building tree 52 of 100\n",
      "building tree 53 of 100\n",
      "building tree 54 of 100\n",
      "building tree 55 of 100\n",
      "building tree 56 of 100\n",
      "building tree 57 of 100\n",
      "building tree 58 of 100\n",
      "building tree 59 of 100\n",
      "building tree 60 of 100\n",
      "building tree 61 of 100\n",
      "building tree 62 of 100\n",
      "building tree 63 of 100\n",
      "building tree 64 of 100\n",
      "building tree 65 of 100\n",
      "building tree 66 of 100\n",
      "building tree 67 of 100\n",
      "building tree 68 of 100\n",
      "building tree 69 of 100\n",
      "building tree 70 of 100\n",
      "building tree 71 of 100\n",
      "building tree 72 of 100\n",
      "building tree 73 of 100\n",
      "building tree 74 of 100\n",
      "building tree 75 of 100\n",
      "building tree 76 of 100\n",
      "building tree 77 of 100\n",
      "building tree 78 of 100\n",
      "building tree 79 of 100\n",
      "building tree 80 of 100\n",
      "building tree 81 of 100\n",
      "building tree 82 of 100\n",
      "building tree 83 of 100\n",
      "building tree 84 of 100\n",
      "building tree 85 of 100\n",
      "building tree 86 of 100\n",
      "building tree 87 of 100\n",
      "building tree 88 of 100\n",
      "building tree 89 of 100\n",
      "building tree 90 of 100\n",
      "building tree 91 of 100\n",
      "building tree 92 of 100\n",
      "building tree 93 of 100\n",
      "building tree 94 of 100\n",
      "building tree 95 of 100\n",
      "building tree 96 of 100\n",
      "building tree 97 of 100\n",
      "building tree 98 of 100\n",
      "building tree 99 of 100\n",
      "building tree 100 of 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:  4.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
       "                      random_state=42, verbose=2, warm_start=False)"
      ]
     },
     "execution_count": 219,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest is the best model performed in Short-term video memorability using C3D, HMP & LBP video features\n",
    "rf = RandomForestRegressor(n_estimators=100,random_state=42,verbose=2)\n",
    "rf.fit(st_X_train,st_Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RDSLzPrbpupN",
    "outputId": "dffcac1f-86de-459b-c274-3664ce447c7f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "st_pred = rf.predict(st_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "id": "0YDpkzGpq_OV"
   },
   "outputs": [],
   "source": [
    "# updating the short-term predictions in ground truth template\n",
    "GT_t['short-term_memorability'] = st_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "id": "RhctWwt6tGhA"
   },
   "outputs": [],
   "source": [
    "# Support Vector Regressor is the best model performed in Long-term video memorability using C3D & HMP video features\n",
    "svg_X = StandardScaler()\n",
    "svg_Y = StandardScaler()\n",
    "lt_X_train = svg_X.fit_transform(lt_X_train)\n",
    "lt_Y_train = svg_Y.fit_transform(lt_Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q_GG_548tGhB",
    "outputId": "66d4f659-b062-4f66-d806-68fbac64968b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
       "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 234,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lt_regressor = SVR(kernel = 'rbf')\n",
    "lt_regressor.fit(lt_X_train,lt_Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "id": "ud_ei5_5tGhD"
   },
   "outputs": [],
   "source": [
    "lt_pred = lt_regressor.predict(lt_X_test)\n",
    "lt_pred = svg_Y.inverse_transform(lt_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "id": "ykfhEb9FumhW"
   },
   "outputs": [],
   "source": [
    "# updating the long-term predictions in ground truth template\n",
    "GT_t['long-term_memorability'] = lt_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "id": "egTj44YB1ZDf"
   },
   "outputs": [],
   "source": [
    "# Saving the Ground Truth csv on the drive\n",
    "os.chdir('/content/drive/MyDrive')\n",
    "# Saving the C3D feature in Google Drive to reuse later  \n",
    "GT_t.to_csv('./Jai_Warde_20210699_Predictions.csv')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Jai_Warde_20210699_Predicting_Memorability.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
